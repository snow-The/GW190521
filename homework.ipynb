{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "L4",
      "authorship_tag": "ABX9TyP9JLFNGIbTyP+YaWULUj9e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snow-The/GW190521/blob/main/homework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# é‡åŠ›æ³¢ GW190521 æ•¸æ“šåˆ†æžèˆ‡ AI è¾¨è­˜å°ˆé¡Œå ±å‘Š\n",
        "\n",
        "æœ¬å°ˆé¡Œæ—¨åœ¨åˆ©ç”¨ä¿¡è™Ÿè™•ç†èˆ‡æ·±åº¦å­¸ç¿’æŠ€è¡“ï¼Œåˆ†æžä¸­ç­‰è³ªé‡é»‘æ´žåˆä½µäº‹ä»¶ GW190521ã€‚\n",
        "å…§å®¹æ¶µè“‹ï¼š\n",
        "\n",
        "1. **åŸºæœ¬é …ç›®**ï¼šæ•¸æ“šä¸‹è¼‰ã€ç™½åŒ– (Whitening)ã€é »è­œåœ–ç¹ªè£½ã€‚\n",
        "2. **é€²éšŽé …ç›® (ç‰©ç†)**ï¼šç‰›é “åŠ›å­¸æ“¬åˆå¤±æ•ˆé©—è­‰ã€Ringdown éˆ´æŒ¯åˆ†æžã€å»£ç¾©ç›¸å°è«–æ³¢å½¢æ“¬åˆã€‚\n",
        "3. **é€²éšŽé …ç›® (AI)**ï¼šåŸºæ–¼ ResNet çš„æ·±åº¦å­¸ç¿’è¨Šè™Ÿè¾¨è­˜ (å« Notch Filter åŽ»å™ªèˆ‡æ¨¡æ“¬æ•¸æ“šå¢žå¼·)ã€‚"
      ],
      "metadata": {
        "id": "VprDKo26Zkdp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ç¬¬ä¸€éƒ¨åˆ†ï¼šç’°å¢ƒå®‰è£èˆ‡è¨­ç½®\n",
        "\n",
        "å®‰è£é‡åŠ›æ³¢åˆ†æžå¿…è¦çš„ Python å¥—ä»¶ (`gwpy`, `ml4gw`, `pycbc` ç­‰)ã€‚"
      ],
      "metadata": {
        "id": "8uhnYYBPZovp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A86Icjg3Mk0D",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# === Cell 1: ç’°å¢ƒå®‰è£èˆ‡è¨­ç½® ===\n",
        "!pip install \"ml4gw>=0.7.10\" \"gwpy>=3.0\" \"h5py>=3.12\" \"torchmetrics>=1.6\" \"lightning>=2.4.0\" \"rich>=10.2.2,<14.0\" \"pycbc\" \"lalsuite\"\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from gwpy.timeseries import TimeSeries\n",
        "from ml4gw.transforms import Whiten, SpectralDensity\n",
        "from scipy.signal import iirnotch, filtfilt, spectrogram, butter\n",
        "from scipy.optimize import curve_fit\n",
        "from pycbc.waveform import get_td_waveform\n",
        "import os\n",
        "\n",
        "# è¨­å®šé‹ç®—è¨­å‚™\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ç¬¬äºŒéƒ¨åˆ†ï¼šæ•¸æ“šç²å–èˆ‡é è™•ç† (åŸºæœ¬é …ç›®)\n",
        "\n",
        "ä¸‹è¼‰ GW190521 ï¼ˆV4ï¼‰åŽŸå§‹æ•¸æ“šï¼ŒåŸ·è¡Œç™½åŒ– (Whitening) ä»¥å£“åˆ¶ä½Žé »é›œè¨Šï¼Œä¸¦ç¹ªè£½åˆæ­¥é »è­œåœ–ã€‚"
      ],
      "metadata": {
        "id": "0ZueNUL4ZwC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 2 (æœ€çµ‚å®Œç¾Žç‰ˆ): æ•¸æ“šä¸‹è¼‰ã€ç™½åŒ–èˆ‡ã€Œå®è§€ vs å¾®è§€ã€é›™è¦–åœ– ===\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from gwpy.timeseries import TimeSeries\n",
        "from ml4gw.transforms import Whiten, SpectralDensity\n",
        "from scipy.signal import spectrogram, butter, filtfilt\n",
        "\n",
        "# 1. åƒæ•¸è¨­å®š\n",
        "trigger_time = 1242442967.4\n",
        "sample_rate = 2048\n",
        "start_time = trigger_time - 6\n",
        "end_time = trigger_time + 2\n",
        "psd_start = start_time - 64\n",
        "psd_end = start_time\n",
        "ifos = [\"H1\", \"L1\"]\n",
        "\n",
        "# 2. ä¸‹è¼‰å‡½æ•¸\n",
        "def get_data(detectors, start, end):\n",
        "    tensors = []\n",
        "    print(f\"Downloading data for {start} to {end}...\")\n",
        "    for det in detectors:\n",
        "        try:\n",
        "            ts = TimeSeries.fetch_open_data(det, start, end, verbose=False)\n",
        "            ts = ts.resample(sample_rate)\n",
        "            if np.isnan(ts.value).any():\n",
        "                ts.value = np.nan_to_num(ts.value)\n",
        "            tensors.append(torch.from_numpy(ts.value.copy()).float())\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to download {det}: {e}\")\n",
        "            return None\n",
        "    return torch.stack(tensors).to(device)\n",
        "\n",
        "# 3. åŸ·è¡Œè™•ç†\n",
        "try:\n",
        "    data_tensor = get_data(ifos, start_time, end_time)\n",
        "    psd_tensor = get_data(ifos, psd_start, psd_end)\n",
        "\n",
        "    if data_tensor is not None and psd_tensor is not None:\n",
        "        # ç™½åŒ–\n",
        "        spectral_density = SpectralDensity(sample_rate=sample_rate, fftlength=2, average=\"median\").to(device)\n",
        "        whiten = Whiten(fduration=2, sample_rate=sample_rate, highpass=20).to(device)\n",
        "\n",
        "        data_batch = data_tensor.unsqueeze(0)\n",
        "        psd_batch = spectral_density(psd_tensor.unsqueeze(0).double())\n",
        "        whitened_batch = whiten(data_batch, psd_batch).float()\n",
        "        whitened_data = whitened_batch\n",
        "\n",
        "        print(\"âœ… æ•¸æ“šè™•ç†å®Œæˆï¼æ­£åœ¨ç¹ªè£½å…©çµ„è¦–åœ–...\")\n",
        "\n",
        "        # æº–å‚™æ•¸æ“š\n",
        "        raw_strain = data_tensor[1].cpu().numpy() # L1\n",
        "        whitened_strain = whitened_data[0, 1].cpu().numpy()\n",
        "\n",
        "        # Bandpass (è®“æ³¢å½¢æ›´ä¹¾æ·¨)\n",
        "        def bandpass_filter(data, fs, low=20, high=100):\n",
        "            nyq = 0.5 * fs\n",
        "            b, a = butter(4, [low/nyq, high/nyq], btype='band')\n",
        "            return filtfilt(b, a, data)\n",
        "        whitened_bp = bandpass_filter(whitened_strain, sample_rate)\n",
        "\n",
        "        # æ™‚é–“è»¸\n",
        "        t_raw = np.linspace(start_time, end_time, len(raw_strain)) - trigger_time\n",
        "        t_white = np.linspace(start_time + 1, end_time - 1, len(whitened_strain)) - trigger_time\n",
        "\n",
        "        # ==========================================\n",
        "        # åœ–ä¸€ï¼šå®è§€å…¨æ™¯ (Global View - 8s)\n",
        "        # ==========================================\n",
        "        fig1, axes1 = plt.subplots(2, 2, figsize=(16, 10))\n",
        "        fig1.suptitle(\"Figure 1: Global View (Full 8s Duration)\", fontsize=16, fontweight='bold')\n",
        "\n",
        "        # å·¦ä¸Šï¼šRaw Time\n",
        "        axes1[0, 0].plot(t_raw, raw_strain, 'gray', alpha=0.8)\n",
        "        axes1[0, 0].set_title(\"Raw Data (Time): Dominated by Low-Freq Noise\")\n",
        "        axes1[0, 0].set_ylabel(\"Strain\"); axes1[0, 0].grid(alpha=0.3)\n",
        "\n",
        "        # å³ä¸Šï¼šProcessed Time\n",
        "        axes1[0, 1].plot(t_white, whitened_bp, 'tab:blue')\n",
        "        axes1[0, 1].set_title(\"Processed Data (Time): Noise Flattened\")\n",
        "        axes1[0, 1].set_ylabel(\"Sigma\"); axes1[0, 1].grid(alpha=0.3)\n",
        "\n",
        "        # å·¦ä¸‹ï¼šRaw Spec\n",
        "        axes1[1, 0].specgram(raw_strain, NFFT=256, Fs=sample_rate, noverlap=128, xextent=[t_raw[0], t_raw[-1]], cmap='inferno', scale='dB')\n",
        "        axes1[1, 0].set_title(\"Raw Spectrogram: High Intensity at Low Freq\")\n",
        "        axes1[1, 0].set_ylabel(\"Freq (Hz)\"); axes1[1, 0].set_yscale('log'); axes1[1, 0].set_ylim(20, 500)\n",
        "\n",
        "        # å³ä¸‹ï¼šProcessed Spec\n",
        "        f, t, Sxx = spectrogram(whitened_strain, fs=sample_rate, nperseg=128, noverlap=120)\n",
        "        axes1[1, 1].pcolormesh(t + t_white[0], f, Sxx, shading='gouraud', cmap='viridis', vmin=0, vmax=10)\n",
        "        axes1[1, 1].set_title(\"Processed Spectrogram: Signal too small to see\")\n",
        "        axes1[1, 1].set_ylabel(\"Freq (Hz)\"); axes1[1, 1].set_ylim(20, 150)\n",
        "\n",
        "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "        plt.show()\n",
        "\n",
        "        # ==========================================\n",
        "        # åœ–äºŒï¼šé¡¯å¾®èšç„¦ (Focused View - 0.6s)\n",
        "        # ==========================================\n",
        "        fig2, axes2 = plt.subplots(2, 2, figsize=(16, 10))\n",
        "        fig2.suptitle(\"Figure 2: Focused View (Zoom-in +/- 0.3s)\", fontsize=16, fontweight='bold')\n",
        "\n",
        "        # è¨­å®š Zoom ç¯„åœ\n",
        "        zoom_range = [-0.3, 0.3]\n",
        "\n",
        "        # å·¦ä¸Šï¼šRaw Time (Zoom)\n",
        "        mask_raw = (t_raw > zoom_range[0]) & (t_raw < zoom_range[1])\n",
        "        axes2[0, 0].plot(t_raw[mask_raw], raw_strain[mask_raw], 'gray', alpha=0.8)\n",
        "        axes2[0, 0].set_title(\"Raw Data (Zoom): Still Random Noise\")\n",
        "        axes2[0, 0].set_ylabel(\"Strain\"); axes2[0, 0].grid(alpha=0.3)\n",
        "\n",
        "        # å³ä¸Šï¼šProcessed Time (Zoom) -> é€™è£¡è¨Šè™Ÿæœƒç¾å½¢ï¼\n",
        "        mask_white = (t_white > zoom_range[0]) & (t_white < zoom_range[1])\n",
        "        axes2[0, 1].plot(t_white[mask_white], whitened_bp[mask_white], 'tab:blue', linewidth=2)\n",
        "        axes2[0, 1].set_title(\"Processed Data (Zoom): GW190521 Waveform Revealed!\")\n",
        "        axes2[0, 1].set_ylabel(\"Sigma\"); axes2[0, 1].grid(alpha=0.3)\n",
        "        # ç•«å€‹è™›ç·šæ¨™ç¤ºä¸­å¿ƒå°±å¥½ï¼Œä¸ç•«ç®­é ­\n",
        "        axes2[0, 1].axvline(0, color='r', linestyle='--', alpha=0.5)\n",
        "\n",
        "        # å·¦ä¸‹ï¼šRaw Spec (Zoom)\n",
        "        axes2[1, 0].specgram(raw_strain, NFFT=256, Fs=sample_rate, noverlap=128, xextent=[t_raw[0], t_raw[-1]], cmap='inferno', scale='dB')\n",
        "        axes2[1, 0].set_title(\"Raw Spectrogram (Zoom): Still Low-Freq Dominant\")\n",
        "        axes2[1, 0].set_ylabel(\"Freq (Hz)\"); axes2[1, 0].set_yscale('log'); axes2[1, 0].set_ylim(20, 500)\n",
        "        axes2[1, 0].set_xlim(zoom_range) # å¼·åˆ¶ Zoom\n",
        "\n",
        "        # å³ä¸‹ï¼šProcessed Spec (Zoom) -> é€™è£¡é »è­œäº®é»žæœƒç¾å½¢ï¼\n",
        "        axes2[1, 1].pcolormesh(t + t_white[0], f, Sxx, shading='gouraud', cmap='viridis', vmin=0, vmax=12)\n",
        "        axes2[1, 1].set_title(\"Processed Spectrogram (Zoom): Clear Merger Signal at 60Hz\")\n",
        "        axes2[1, 1].set_ylabel(\"Freq (Hz)\"); axes2[1, 1].set_ylim(20, 150)\n",
        "        axes2[1, 1].set_xlim(zoom_range) # å¼·åˆ¶ Zoom\n",
        "\n",
        "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "        plt.show()\n",
        "\n",
        "        print(\"âœ… é›™è¦–åœ–ç¹ªè£½å®Œæˆï¼\")\n",
        "        print(\"åœ–ä¸€å±•ç¤ºäº†ã€Žå¤§æµ·æ’ˆé‡ã€çš„é›£åº¦ï¼Œåœ–äºŒå±•ç¤ºäº†ã€Žæ•¸æ“šè™•ç†ã€çš„å¨åŠ›ã€‚\")\n",
        "\n",
        "    else:\n",
        "        print(\"âŒ æ•¸æ“šä¸‹è¼‰å¤±æ•—ã€‚\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error: {e}\")"
      ],
      "metadata": {
        "id": "XVBpDCM_Z6m5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ç¬¬ä¸‰éƒ¨åˆ†ï¼šç‰©ç†åˆ†æž (é€²éšŽé …ç›® 1 & 2)\n",
        "\n",
        "åŒ…å«ï¼š\n",
        "\n",
        "1. **ç‰›é “åŠ›å­¸æ“¬åˆ (Inspiral)**ï¼šè­‰æ˜Žç°¡å–®ç‰›é “æ¨¡åž‹ç„¡æ³•è§£é‡‹æ­¤äº‹ä»¶ï¼ˆç´…ç·šä¸å»åˆï¼‰ã€‚\n",
        "2. **å»£ç¾©ç›¸å°è«–æ“¬åˆ (IMRPhenom)**ï¼šä½¿ç”¨ PyCBC ç”Ÿæˆç›¸å°è«–æ³¢å½¢ï¼Œå®Œç¾Žé‡ç¾è¨Šè™Ÿï¼ˆç™½ç·šå»åˆï¼‰ã€‚\n",
        "3. **Ringdown åˆ†æž**ï¼šæ“¬åˆåˆä½µå¾Œçš„éˆ´æŒ¯æ³¢å½¢ï¼ŒæŽ¨ç®—é»‘æ´žé »çŽ‡ã€‚"
      ],
      "metadata": {
        "id": "5sZqShdEaCnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 3: ç‰©ç†åˆ†æž (ç‰›é “ vs ç›¸å°è«– + Ringdown) ===\n",
        "if 'whitened_data' not in globals():\n",
        "    print(\"âŒ è«‹å…ˆåŸ·è¡Œ Cell 2ï¼\")\n",
        "else:\n",
        "    strain_l1 = whitened_data[0, 1].cpu().numpy()\n",
        "    plot_start = start_time + 1\n",
        "    plot_end = end_time - 1\n",
        "    time_axis = np.linspace(plot_start, plot_end, len(strain_l1))\n",
        "\n",
        "    plt.figure(figsize=(14, 12))\n",
        "\n",
        "    # --- ä¸Šåœ–ï¼šInspiral & Merger ---\n",
        "    plt.subplot(2, 1, 1)\n",
        "    fs = sample_rate\n",
        "    f_vec, t_vec, Sxx = spectrogram(strain_l1, fs, nperseg=int(fs/16), noverlap=int(fs/16*0.95))\n",
        "    plt.pcolormesh(t_vec + plot_start, f_vec, Sxx, shading='gouraud', cmap='viridis', vmin=0, vmax=15)\n",
        "\n",
        "    # ç‰›é “åŠ›å­¸ (ç´…è™›ç·š)\n",
        "    G, c, M_solar = 6.674e-11, 3e8, 1.989e30\n",
        "    m1, m2 = 85 * M_solar, 66 * M_solar\n",
        "    chirp_mass = (m1 * m2)**(3/5) / (m1 + m2)**(1/5)\n",
        "    def newtonian_freq(t, tc):\n",
        "        tau = tc - t\n",
        "        with np.errstate(invalid='ignore'):\n",
        "            return (c**3)/(8*np.pi*G*chirp_mass) * ((5*G*chirp_mass)/(c**3*tau))**(3/8)\n",
        "\n",
        "    t_model = np.linspace(trigger_time - 1.5, trigger_time, 1000)\n",
        "    plt.plot(t_model, newtonian_freq(t_model, trigger_time+0.02), 'r--', linewidth=3, label='Newtonian')\n",
        "\n",
        "    # å»£ç¾©ç›¸å°è«– (ç™½å¯¦ç·š)\n",
        "    hp, _ = get_td_waveform(approximant=\"IMRPhenomXPHM\", mass1=95, mass2=69, spin1z=0.7, spin2z=0.7, delta_t=1.0/fs, f_lower=20)\n",
        "    hp.resize(len(hp))\n",
        "    rel_time = hp.sample_times.numpy() + (trigger_time - hp.sample_times[-1])\n",
        "    plt.plot(rel_time, hp.numpy() * 400 * 1e19 + 60, 'w-', linewidth=2, alpha=0.9, label='GR Waveform')\n",
        "\n",
        "    plt.yscale('log'); plt.ylim(20, 150); plt.xlim(trigger_time-0.5, trigger_time+0.2)\n",
        "    plt.title(\"Part 1: Newtonian vs GR\", fontsize=14, fontweight='bold'); plt.legend(loc='upper left')\n",
        "\n",
        "    # --- ä¸‹åœ–ï¼šRingdown ---\n",
        "    plt.subplot(2, 1, 2)\n",
        "    peak_idx = np.argmax(np.abs(strain_l1[(time_axis > trigger_time-0.1) & (time_axis < trigger_time+0.1)]))\n",
        "    global_peak_idx = np.where((time_axis > trigger_time-0.1))[0][0] + peak_idx\n",
        "\n",
        "    start_fit = global_peak_idx + int(0.003 * fs)\n",
        "    end_fit = global_peak_idx + int(0.05 * fs)\n",
        "    t_ring = time_axis[start_fit:end_fit]\n",
        "    h_ring = strain_l1[start_fit:end_fit]\n",
        "\n",
        "    def ringdown_model(t, A, tau, f, phi):\n",
        "        return A * np.exp(-(t-t[0])/tau) * np.cos(2*np.pi*f*(t-t[0]) + phi)\n",
        "\n",
        "    try:\n",
        "        popt, _ = curve_fit(ringdown_model, t_ring, h_ring, p0=[np.max(h_ring), 0.01, 65, 0])\n",
        "        plt.plot(time_axis, strain_l1, 'k-', alpha=0.3)\n",
        "        plt.plot(t_ring, ringdown_model(t_ring, *popt), 'r-', linewidth=2.5, label=f'Fit (f={popt[2]:.1f}Hz)')\n",
        "        plt.xlim(trigger_time-0.05, trigger_time+0.1)\n",
        "        plt.title(f\"Part 2: Ringdown (f={popt[2]:.1f} Hz)\", fontsize=14, fontweight='bold'); plt.legend()\n",
        "    except:\n",
        "        print(\"Ringdown fit failed\")\n",
        "\n",
        "    plt.tight_layout(); plt.show()"
      ],
      "metadata": {
        "id": "qY5SlFTiaKOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## ç¬¬å››éƒ¨åˆ†ï¼šæ·±åº¦å­¸ç¿’è¨Šè™Ÿè¾¨è­˜ (é€²éšŽé …ç›® 3)\n",
        "\n",
        "ä½¿ç”¨ ResNet-18 é€²è¡Œã€Œæœ‰ç›£ç£å­¸ç¿’ã€ã€‚\n",
        "\n",
        "* **æ•¸æ“šå¢žå¼·**ï¼šåˆ©ç”¨ `IMRPhenomXPHM` ç”Ÿæˆæ¨¡æ“¬æ³¢å½¢ï¼Œä¸¦æ··åˆçœŸå¯¦é›œè¨Šç‰¹å¾µã€‚\n",
        "* **åŽ»å™ªè™•ç†**ï¼šå¯¦æ–½ Notch Filter (60Hz) ç§»é™¤é›»æºç·šå¹²æ“¾ (PhysRevLett.125.101102æåˆ°) ã€‚\n",
        "* **å¯¦æˆ°é©—è­‰**ï¼šå°‡æ¨¡åž‹æ‡‰ç”¨æ–¼çœŸå¯¦ GW190521 æ•¸æ“šã€‚"
      ],
      "metadata": {
        "id": "dAGwQ1azaSn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 4: AI æ•¸æ“šç”Ÿæˆ (å¤šæ ¸å¿ƒåŠ é€Ÿç‰ˆ) ===\n",
        "import concurrent.futures\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "DATA_FILE = \"gw190521_dataset.pt\"\n",
        "NUM_SAMPLES = 12000 # æ¨£æœ¬æ•¸\n",
        "\n",
        "# å·¥å…·å‡½æ•¸\n",
        "def apply_notch(data, fs=2048):\n",
        "    data = np.nan_to_num(data)\n",
        "    for f in [60, 120, 180]:\n",
        "        b, a = iirnotch(f, 30, fs)\n",
        "        data = filtfilt(b, a, data)\n",
        "    return np.nan_to_num(data)\n",
        "\n",
        "def get_ai_spec(strain, fs=2048):\n",
        "    f, t, Sxx = spectrogram(strain, fs=fs, nperseg=256, noverlap=240)\n",
        "    mask = (f >= 20) & (f <= 300)\n",
        "    spec = np.log(Sxx[mask, :] + 1e-10)\n",
        "    spec = np.clip(spec, np.mean(spec)-2.5*np.std(spec), np.mean(spec)+2.5*np.std(spec))\n",
        "    return (spec - np.min(spec)) / (np.max(spec) - np.min(spec) + 1e-8)\n",
        "\n",
        "def worker(i):\n",
        "    np.random.seed(int.from_bytes(os.urandom(4), 'little'))\n",
        "    N = int(2048 * 1.0)\n",
        "    noise = np.random.normal(0, 1, N)\n",
        "    if i % 2 == 0: # Signal\n",
        "        hp, _ = get_td_waveform(approximant=\"IMRPhenomXPHM\", mass1=np.random.uniform(50,100),\n",
        "                                mass2=np.random.uniform(30,80), delta_t=1.0/2048, f_lower=20)\n",
        "        hp.resize(N)\n",
        "        sig = hp.numpy() * 1e19 * np.random.uniform(0.5, 4.0)\n",
        "        shift = np.random.randint(0, N-len(sig) if N>len(sig) else 1)\n",
        "        noise[shift:shift+len(sig)] += sig[:len(noise)-shift]\n",
        "        return get_ai_spec(apply_notch(noise)), 1.0\n",
        "    else: # Noise\n",
        "        return get_ai_spec(apply_notch(noise)), 0.0\n",
        "\n",
        "if not os.path.exists(DATA_FILE):\n",
        "    print(\"ðŸš€ é–‹å§‹ç”Ÿæˆæ•¸æ“š...\")\n",
        "    with concurrent.futures.ProcessPoolExecutor() as ex:\n",
        "        results = list(tqdm(ex.map(worker, range(NUM_SAMPLES)), total=NUM_SAMPLES))\n",
        "\n",
        "    data, labels = zip(*results)\n",
        "    torch.save({\"data\": torch.tensor(np.array(data)).unsqueeze(1).float(),\n",
        "                \"labels\": torch.tensor(np.array(labels)).unsqueeze(1).float()}, DATA_FILE)\n",
        "    print(\"âœ… æ•¸æ“šå­˜æª”å®Œæˆï¼\")\n",
        "else:\n",
        "    print(\"âš ï¸ æ•¸æ“šæª”å·²å­˜åœ¨ï¼Œè·³éŽç”Ÿæˆã€‚\")"
      ],
      "metadata": {
        "id": "WW72Lz3saYuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 5 (æœ€çµ‚ä¿®å¾©ç‰ˆ): æ¨¡åž‹è¨“ç·´ (å«æ•¸æ“šå¢žå¼·ã€ä¿®å¾© Scheduler å ±éŒ¯) ===\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import os\n",
        "\n",
        "# è¨­å®šé‹ç®—è¨­å‚™ (ç¢ºä¿èˆ‡å‰é¢ä¸€è‡´)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "DATA_FILE = \"gw190521_dataset.pt\"\n",
        "\n",
        "# å®šç¾©ä¸€å€‹æ”¯æ´ Augmentation çš„è³‡æ–™é›†é¡žåˆ¥\n",
        "class AugmentedDataset(Dataset):\n",
        "    def __init__(self, tensors, labels, transform=None):\n",
        "        self.tensors = tensors\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.tensors[index]\n",
        "        y = self.labels[index]\n",
        "        if self.transform:\n",
        "            # x çš„å½¢ç‹€æ˜¯ (1, Freq, Time)ï¼ŒTransform æœƒè‡ªå‹•è™•ç†\n",
        "            x = self.transform(x)\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tensors)\n",
        "\n",
        "if os.path.exists(DATA_FILE):\n",
        "    # 1. è¼‰å…¥æ•¸æ“š\n",
        "    saved = torch.load(DATA_FILE)\n",
        "    full_data = saved[\"data\"]\n",
        "    full_labels = saved[\"labels\"]\n",
        "\n",
        "    # æª¢æŸ¥æ•¸æ“šå¹³è¡¡æ€§\n",
        "    sig_count = (full_labels == 1.0).sum().item()\n",
        "    print(f\"ðŸ“Š æ•¸æ“šè¼‰å…¥æˆåŠŸ: ç¸½æ•¸ {len(full_labels)} | è¨Šè™Ÿ {sig_count} | é›œè¨Š {len(full_labels)-sig_count}\")\n",
        "\n",
        "    # 2. å®šç¾©æ•¸æ“šå¢žå¼· (Data Augmentation) - é€™è£¡å°±æ˜¯ä½ è¦çš„ç‰¹è¨“ï¼\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(p=0.5), # é€™å€‹ä¿ç•™ï¼Œå¾ˆæœ‰ç”¨\n",
        "        # æš«æ™‚é—œæŽ‰æ—‹è½‰å’Œé®æ“‹ï¼Œå…ˆæ±‚æœ‰å†æ±‚å¥½\n",
        "        # transforms.RandomApply([transforms.RandomRotation(degrees=5)], p=0.3),\n",
        "        # transforms.RandomErasing(p=0.2, scale=(0.02, 0.1), ratio=(0.3, 3.3))\n",
        "    ])\n",
        "\n",
        "    # 3. åˆ†å‰²è¨“ç·´èˆ‡é©—è­‰é›†\n",
        "    total_len = len(full_data)\n",
        "    train_len = int(0.8 * total_len)\n",
        "    val_len = total_len - train_len\n",
        "\n",
        "    # éš¨æ©Ÿæ‰“äº‚ç´¢å¼•\n",
        "    generator = torch.Generator().manual_seed(42) # å›ºå®šç¨®å­ä»¥æ±‚é‡ç¾\n",
        "    perm = torch.randperm(total_len, generator=generator)\n",
        "    train_idx = perm[:train_len]\n",
        "    val_idx = perm[train_len:]\n",
        "\n",
        "    # å»ºç«‹ Dataset (åªæœ‰è¨“ç·´é›†å¥—ç”¨ transform)\n",
        "    train_ds = AugmentedDataset(full_data[train_idx], full_labels[train_idx], transform=train_transform)\n",
        "    val_ds = AugmentedDataset(full_data[val_idx], full_labels[val_idx], transform=None)\n",
        "\n",
        "    # å»ºç«‹ DataLoader (Batch Size è¨­ç‚º 32 æˆ– 64)\n",
        "    train_dl = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "    val_dl = DataLoader(val_ds, batch_size=64)\n",
        "\n",
        "    # 4. å®šç¾©æ¨¡åž‹ (ResNet18)\n",
        "    model = models.resnet18(weights=None)\n",
        "    # ä¿®æ”¹ç¬¬ä¸€å±¤ (è¼¸å…¥é€šé“æ”¹ç‚º 1)\n",
        "    model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "    # ä¿®æ”¹æœ€å¾Œä¸€å±¤ (è¼¸å‡ºæ”¹ç‚º 1)\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Dropout(0.5), # Dropout é˜²æ­¢éŽæ“¬åˆ\n",
        "        nn.Linear(model.fc.in_features, 1)\n",
        "    )\n",
        "    model = model.to(device)\n",
        "\n",
        "    # å„ªåŒ–å™¨èˆ‡ Loss\n",
        "    # ä½¿ç”¨ AdamW åŠ ä¸Š Weight Decay ä¾†æŠ‘åˆ¶éŽæ“¬åˆ\n",
        "    opt = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-3)\n",
        "    crit = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # å­¸ç¿’çŽ‡èª¿åº¦å™¨ (ä¿®æ­£ç‰ˆï¼šç§»é™¤äº† verbose=True)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(opt, mode='max', factor=0.5, patience=3)\n",
        "\n",
        "    # 5. è¨“ç·´è¿´åœˆ\n",
        "    hist = {'train_loss':[], 'val_loss':[], 'val_acc':[]}\n",
        "    best_acc = 0.0\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    epochs = 15\n",
        "    print(f\"ðŸš€ é–‹å§‹è¨“ç·´ç¾Žå°‘å¥³ AI (ResNet18) - å…± {epochs} è¼ª...\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        run_loss = 0\n",
        "\n",
        "        # è¨“ç·´éšŽæ®µ\n",
        "        for x, y in train_dl:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            opt.zero_grad()\n",
        "            out = model(x)\n",
        "            loss = crit(out, y)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            run_loss += loss.item()\n",
        "\n",
        "        # é©—è­‰éšŽæ®µ\n",
        "        model.eval()\n",
        "        val_loss, correct = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for x, y in val_dl:\n",
        "                x, y = x.to(device), y.to(device)\n",
        "                out = model(x)\n",
        "                val_loss += crit(out, y).item()\n",
        "                # é æ¸¬ > 0.5 (ç¶“éŽ Sigmoid å¾Œ) ç‚ºè¨Šè™Ÿ\n",
        "                predicted = (torch.sigmoid(out) > 0.5).float()\n",
        "                correct += (predicted == y).sum().item()\n",
        "\n",
        "        # çµ±è¨ˆæ•¸æ“š\n",
        "        epoch_loss = run_loss / len(train_dl)\n",
        "        epoch_val_loss = val_loss / len(val_dl)\n",
        "        epoch_acc = correct / len(val_ds)\n",
        "        current_lr = opt.param_groups[0]['lr']\n",
        "\n",
        "        hist['train_loss'].append(epoch_loss)\n",
        "        hist['val_loss'].append(epoch_val_loss)\n",
        "        hist['val_acc'].append(epoch_acc)\n",
        "\n",
        "        # æ›´æ–° Scheduler (æ ¹æ“šé©—è­‰æº–ç¢ºçŽ‡)\n",
        "        scheduler.step(epoch_acc)\n",
        "\n",
        "        # é¡¯ç¤ºé€²åº¦èˆ‡å„²å­˜æœ€ä½³æ¨¡åž‹\n",
        "        if epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            print(f\"Epoch {epoch+1:02d} | ðŸŸ¢ Train: {epoch_loss:.4f} | Val: {epoch_val_loss:.4f} | Acc: {epoch_acc:.2%} | LR: {current_lr:.1e} (New Best!)\")\n",
        "        else:\n",
        "            print(f\"Epoch {epoch+1:02d} | âšª Train: {epoch_loss:.4f} | Val: {epoch_val_loss:.4f} | Acc: {epoch_acc:.2%} | LR: {current_lr:.1e}\")\n",
        "\n",
        "    # 6. è¨“ç·´çµæŸï¼Œè¼‰å…¥æœ€ä½³æ¬Šé‡\n",
        "    print(\"-\" * 70)\n",
        "    print(f\"ðŸ† è¨“ç·´å®Œæˆï¼æœ€ä½³é©—è­‰æº–ç¢ºçŽ‡: {best_acc:.2%}\")\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    # ç¹ªè£½åœ–è¡¨\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(hist['train_loss'], label='Train Loss', color='tab:blue')\n",
        "    plt.plot(hist['val_loss'], label='Val Loss', color='tab:orange')\n",
        "    plt.title(\"Loss Curve (Lower is Better)\")\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend(); plt.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(hist['val_acc'], label='Val Accuracy', color='tab:green')\n",
        "    plt.title(\"Accuracy Curve (Higher is Better)\")\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.legend(); plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"âŒ æ‰¾ä¸åˆ°æ•¸æ“šæª”ï¼Œè«‹å…ˆåŸ·è¡Œ Cell 4 ç”Ÿæˆæ•¸æ“šï¼\")"
      ],
      "metadata": {
        "id": "-EMv86Z2h5qR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 6: æœ€çµ‚ AI é©—æ”¶ (Signal vs Noise) ===\n",
        "# ç¢ºä¿ä½¿ç”¨èˆ‡è¨“ç·´ä¸€è‡´çš„é è™•ç†\n",
        "def get_ai_spec(strain, fs=2048):\n",
        "    f, t, Sxx = spectrogram(strain, fs=fs, nperseg=256, noverlap=240)\n",
        "    mask = (f >= 20) & (f <= 300)\n",
        "    spec = np.log(Sxx[mask, :] + 1e-10)\n",
        "    spec = np.clip(spec, np.mean(spec)-2.5*np.std(spec), np.mean(spec)+2.5*np.std(spec))\n",
        "    return (spec - np.min(spec)) / (np.max(spec) - np.min(spec) + 1e-8), t, f[mask]\n",
        "\n",
        "# æŠ“å–çœŸå¯¦æ•¸æ“š\n",
        "idx_sig = int(5.0 * sample_rate)\n",
        "idx_noise = int(2.0 * sample_rate)\n",
        "hw = int(0.5 * sample_rate)\n",
        "\n",
        "sig_data = whitened_data[0, 1, idx_sig-hw:idx_sig+hw].cpu().numpy()\n",
        "noise_data = whitened_data[0, 1, idx_noise-hw:idx_noise+hw].cpu().numpy()\n",
        "\n",
        "# é æ¸¬\n",
        "model.eval()\n",
        "spec_sig, _, f_axis = get_ai_spec(sig_data)\n",
        "spec_noise, _, _ = get_ai_spec(noise_data)\n",
        "\n",
        "with torch.no_grad():\n",
        "    score_sig = torch.sigmoid(model(torch.tensor(spec_sig).unsqueeze(0).unsqueeze(0).float().to(device))).item()\n",
        "    score_noise = torch.sigmoid(model(torch.tensor(spec_noise).unsqueeze(0).unsqueeze(0).float().to(device))).item()\n",
        "\n",
        "# ç¹ªåœ–\n",
        "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
        "ax[0].imshow(spec_sig, origin='lower', aspect='auto', cmap='viridis', extent=[-0.5, 0.5, f_axis[0], f_axis[-1]])\n",
        "ax[0].set_title(f\"Target: Signal\\nConf: {score_sig:.4f}\", color='green', fontweight='bold')\n",
        "ax[0].axvline(0, color='r', linestyle='--')\n",
        "\n",
        "ax[1].imshow(spec_noise, origin='lower', aspect='auto', cmap='viridis', extent=[-0.5, 0.5, f_axis[0], f_axis[-1]])\n",
        "ax[1].set_title(f\"Control: Noise\\nConf: {score_noise:.4f}\", color='black', fontweight='bold')\n",
        "\n",
        "plt.show()\n",
        "print(f\"ðŸš€ AI åˆ¤æ–·ï¼šè¨Šè™Ÿä¿¡å¿ƒåº¦ {score_sig:.2%} | é›œè¨Šèª¤åˆ¤çŽ‡ {score_noise:.2%}\")"
      ],
      "metadata": {
        "id": "SJnqc1EAjsLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 7 (ä¿®æ­£ç‰ˆ): è£½ä½œæ³¢å½¢æŽƒæå‹•ç•«ä¸¦å­˜æª” (MP4/GIF) ===\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from matplotlib import rc\n",
        "import numpy as np\n",
        "\n",
        "# 1. è§£é™¤å‹•ç•«å¤§å°é™åˆ¶ (è¨­ç‚º 100MB)\n",
        "plt.rcParams['animation.embed_limit'] = 100.0\n",
        "# è¨­å®š ffmpeg (ç”¨æ–¼ç”Ÿæˆ MP4)\n",
        "rc('animation', html='jshtml')\n",
        "\n",
        "print(\"æ­£åœ¨è£½ä½œä¸¦å„²å­˜å‹•ç•«ï¼Œè«‹ç¨å€™...\")\n",
        "\n",
        "# 2. æº–å‚™æ•¸æ“š\n",
        "# ç‚ºäº†é¿å…æª”æ¡ˆéŽå¤§ï¼Œæˆ‘å€‘åªå–æœ€ç²¾å½©çš„ 1 ç§’é˜ (Trigger å‰å¾Œ 0.5s)\n",
        "center_idx = int(5.0 * sample_rate)\n",
        "window = int(0.5 * sample_rate)\n",
        "data_anim = whitened_data[0, 1, center_idx-window : center_idx+window].cpu().numpy()\n",
        "\n",
        "# ç°¡å–®æ¿¾æ³¢è®“ç·šæ¢å¥½çœ‹é»ž\n",
        "def apply_notch_anim(data, fs=2048):\n",
        "    from scipy.signal import iirnotch, filtfilt\n",
        "    data = np.nan_to_num(data)\n",
        "    for f in [60, 120, 180]:\n",
        "        b, a = iirnotch(f, 30, fs)\n",
        "        data = filtfilt(b, a, data)\n",
        "    return data\n",
        "\n",
        "data_anim = apply_notch_anim(data_anim, sample_rate)\n",
        "t_anim = np.linspace(-0.5, 0.5, len(data_anim))\n",
        "\n",
        "# 3. è¨­å®šç•«å¸ƒ (èª¿æ•´ figsize å’Œ DPI ä»¥æŽ§åˆ¶æª”æ¡ˆå¤§å°)\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 6), dpi=100, sharex=True)\n",
        "\n",
        "# ä¸Šåœ–ï¼šæ³¢å½¢\n",
        "line, = ax1.plot([], [], 'w-', linewidth=1.5)\n",
        "ax1.set_xlim(-0.5, 0.2)\n",
        "ax1.set_ylim(-6, 6)\n",
        "ax1.set_facecolor('black')\n",
        "ax1.set_ylabel('Strain', color='white')\n",
        "ax1.set_title('GW190521 Merger Event', fontsize=14)\n",
        "ax1.grid(True, alpha=0.3, color='gray')\n",
        "\n",
        "# ä¸‹åœ–ï¼šé »è­œåœ–\n",
        "from scipy.signal import spectrogram\n",
        "f, t, Sxx = spectrogram(data_anim, fs=sample_rate, nperseg=128, noverlap=120)\n",
        "t = t - 0.5 # æ ¡æ­£æ™‚é–“\n",
        "mesh = ax2.pcolormesh(t, f, Sxx, shading='gouraud', cmap='viridis', vmin=0, vmax=10)\n",
        "ax2.set_ylabel('Frequency (Hz)')\n",
        "ax2.set_xlabel('Time (s)')\n",
        "ax2.set_ylim(20, 150)\n",
        "ax2.set_facecolor('black')\n",
        "\n",
        "# æŽƒæç·š\n",
        "vline1 = ax1.axvline(x=-0.5, color='r', linestyle='--')\n",
        "vline2 = ax2.axvline(x=-0.5, color='r', linestyle='--')\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# 4. æ›´æ–°å‡½æ•¸\n",
        "def update(frame):\n",
        "    current_time = t_anim[frame]\n",
        "    # æ›´æ–°æ³¢å½¢\n",
        "    line.set_data(t_anim[:frame], data_anim[:frame])\n",
        "    # æ›´æ–°æŽƒæç·š\n",
        "    vline1.set_xdata([current_time])\n",
        "    vline2.set_xdata([current_time])\n",
        "    return line, vline1, vline2\n",
        "\n",
        "# 5. ç”Ÿæˆå‹•ç•« (é™ä½ŽæŽ¡æ¨£çŽ‡ Step=4 ä»¥ç¸®å°é«”ç©)\n",
        "step = 4\n",
        "frames = range(0, len(t_anim), step)\n",
        "ani = animation.FuncAnimation(fig, update, frames=frames, interval=20, blit=True)\n",
        "\n",
        "# === é—œéµä¿®æ”¹ï¼šå­˜æˆç¨ç«‹æª”æ¡ˆ ===\n",
        "# å„²å­˜ MP4 (PPT é¦–é¸ï¼Œç•«è³ªå¥½é«”ç©å°)\n",
        "print(\"æ­£åœ¨å„²å­˜ç‚º gw190521.mp4 ...\")\n",
        "ani.save('gw190521.mp4', writer='ffmpeg', fps=30)\n",
        "\n",
        "# å„²å­˜ GIF (å‚™ç”¨ï¼Œç›¸å®¹æ€§é«˜ä½†é«”ç©å¤§)\n",
        "print(\"æ­£åœ¨å„²å­˜ç‚º gw190521.gif ...\")\n",
        "ani.save('gw190521.gif', writer='pillow', fps=15)\n",
        "\n",
        "plt.close()\n",
        "print(\"âœ… å‹•ç•«è£½ä½œå®Œæˆï¼\")\n",
        "print(\"ðŸ“¥ è«‹æŸ¥çœ‹å·¦å´æª”æ¡ˆæ¬„ (Files)ï¼Œä¸‹è¼‰ 'gw190521.mp4' æˆ– 'gw190521.gif' æ”¾å…¥æŠ•å½±ç‰‡ã€‚\")"
      ],
      "metadata": {
        "id": "B7RKsRvhox0L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}