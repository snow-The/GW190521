{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "L4",
      "authorship_tag": "ABX9TyOfX77Lrvd3mwgTL4jrPOMZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snow-The/GW190521/blob/main/homework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ÈáçÂäõÊ≥¢ GW190521 Êï∏ÊìöÂàÜÊûêËàá AI Ëæ®Ë≠òÂ∞àÈ°åÂ†±Âëä\n",
        "\n",
        "Êú¨Â∞àÈ°åÊó®Âú®Âà©Áî®‰ø°ËôüËôïÁêÜËàáÊ∑±Â∫¶Â≠∏ÁøíÊäÄË°ìÔºåÂàÜÊûê‰∏≠Á≠âË≥™ÈáèÈªëÊ¥ûÂêà‰Ωµ‰∫ã‰ª∂ GW190521„ÄÇ\n",
        "ÂÖßÂÆπÊ∂µËìãÔºö\n",
        "\n",
        "1. **Âü∫Êú¨È†ÖÁõÆ**ÔºöÊï∏Êìö‰∏ãËºâ„ÄÅÁôΩÂåñ (Whitening)„ÄÅÈ†ªË≠úÂúñÁπ™Ë£Ω„ÄÇ\n",
        "2. **ÈÄ≤ÈöéÈ†ÖÁõÆ (Áâ©ÁêÜ)**ÔºöÁâõÈ†ìÂäõÂ≠∏Êì¨ÂêàÂ§±ÊïàÈ©óË≠â„ÄÅRingdown Èà¥ÊåØÂàÜÊûê„ÄÅÂª£Áæ©Áõ∏Â∞çË´ñÊ≥¢ÂΩ¢Êì¨Âêà„ÄÇ\n",
        "3. **ÈÄ≤ÈöéÈ†ÖÁõÆ (AI)**ÔºöÂü∫Êñº ResNet ÁöÑÊ∑±Â∫¶Â≠∏ÁøíË®äËôüËæ®Ë≠ò (Âê´ Notch Filter ÂéªÂô™ËàáÊ®°Êì¨Êï∏ÊìöÂ¢ûÂº∑)„ÄÇ"
      ],
      "metadata": {
        "id": "VprDKo26Zkdp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Á¨¨‰∏ÄÈÉ®ÂàÜÔºöÁí∞Â¢ÉÂÆâË£ùËàáË®≠ÁΩÆ\n",
        "\n",
        "ÂÆâË£ùÈáçÂäõÊ≥¢ÂàÜÊûêÂøÖË¶ÅÁöÑ Python Â•ó‰ª∂ (`gwpy`, `ml4gw`, `pycbc` Á≠â)„ÄÇ"
      ],
      "metadata": {
        "id": "8uhnYYBPZovp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A86Icjg3Mk0D",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# === Cell 1: Áí∞Â¢ÉÂÆâË£ùËàáË®≠ÁΩÆ ===\n",
        "!pip install \"ml4gw>=0.7.10\" \"gwpy>=3.0\" \"h5py>=3.12\" \"torchmetrics>=1.6\" \"lightning>=2.4.0\" \"rich>=10.2.2,<14.0\" \"pycbc\" \"lalsuite\"\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from gwpy.timeseries import TimeSeries\n",
        "from ml4gw.transforms import Whiten, SpectralDensity\n",
        "from scipy.signal import iirnotch, filtfilt, spectrogram, butter\n",
        "from scipy.optimize import curve_fit\n",
        "from pycbc.waveform import get_td_waveform\n",
        "import os\n",
        "\n",
        "# Ë®≠ÂÆöÈÅãÁÆóË®≠ÂÇô\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Á¨¨‰∫åÈÉ®ÂàÜÔºöÊï∏ÊìöÁç≤ÂèñËàáÈ†êËôïÁêÜ (Âü∫Êú¨È†ÖÁõÆ)\n",
        "\n",
        "‰∏ãËºâ GW190521 ÔºàV4ÔºâÂéüÂßãÊï∏ÊìöÔºåÂü∑Ë°åÁôΩÂåñ (Whitening) ‰ª•Â£ìÂà∂‰ΩéÈ†ªÈõúË®äÔºå‰∏¶Áπ™Ë£ΩÂàùÊ≠•È†ªË≠úÂúñ„ÄÇ"
      ],
      "metadata": {
        "id": "0ZueNUL4ZwC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 2 (ÊúÄÁµÇÂÆåÁæéÁâà): Êï∏Êìö‰∏ãËºâ„ÄÅÁôΩÂåñËàá„ÄåÂÆèËßÄ vs ÂæÆËßÄ„ÄçÈõôË¶ñÂúñ ===\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from gwpy.timeseries import TimeSeries\n",
        "from ml4gw.transforms import Whiten, SpectralDensity\n",
        "from scipy.signal import spectrogram, butter, filtfilt\n",
        "\n",
        "# 1. ÂèÉÊï∏Ë®≠ÂÆö\n",
        "trigger_time = 1242442967.4\n",
        "sample_rate = 2048\n",
        "start_time = trigger_time - 6\n",
        "end_time = trigger_time + 2\n",
        "psd_start = start_time - 64\n",
        "psd_end = start_time\n",
        "ifos = [\"H1\", \"L1\"]\n",
        "\n",
        "# 2. ‰∏ãËºâÂáΩÊï∏\n",
        "def get_data(detectors, start, end):\n",
        "    tensors = []\n",
        "    print(f\"Downloading data for {start} to {end}...\")\n",
        "    for det in detectors:\n",
        "        try:\n",
        "            ts = TimeSeries.fetch_open_data(det, start, end, verbose=False)\n",
        "            ts = ts.resample(sample_rate)\n",
        "            if np.isnan(ts.value).any():\n",
        "                ts.value = np.nan_to_num(ts.value)\n",
        "            tensors.append(torch.from_numpy(ts.value.copy()).float())\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to download {det}: {e}\")\n",
        "            return None\n",
        "    return torch.stack(tensors).to(device)\n",
        "\n",
        "# 3. Âü∑Ë°åËôïÁêÜ\n",
        "try:\n",
        "    data_tensor = get_data(ifos, start_time, end_time)\n",
        "    psd_tensor = get_data(ifos, psd_start, psd_end)\n",
        "\n",
        "    if data_tensor is not None and psd_tensor is not None:\n",
        "        # ÁôΩÂåñ\n",
        "        spectral_density = SpectralDensity(sample_rate=sample_rate, fftlength=2, average=\"median\").to(device)\n",
        "        whiten = Whiten(fduration=2, sample_rate=sample_rate, highpass=20).to(device)\n",
        "\n",
        "        data_batch = data_tensor.unsqueeze(0)\n",
        "        psd_batch = spectral_density(psd_tensor.unsqueeze(0).double())\n",
        "        whitened_batch = whiten(data_batch, psd_batch).float()\n",
        "        whitened_data = whitened_batch\n",
        "\n",
        "        print(\"‚úÖ Êï∏ÊìöËôïÁêÜÂÆåÊàêÔºÅÊ≠£Âú®Áπ™Ë£ΩÂÖ©ÁµÑË¶ñÂúñ...\")\n",
        "\n",
        "        # Ê∫ñÂÇôÊï∏Êìö\n",
        "        raw_strain = data_tensor[1].cpu().numpy() # L1\n",
        "        whitened_strain = whitened_data[0, 1].cpu().numpy()\n",
        "\n",
        "        # Bandpass (ËÆìÊ≥¢ÂΩ¢Êõ¥‰πæÊ∑®)\n",
        "        def bandpass_filter(data, fs, low=20, high=100):\n",
        "            nyq = 0.5 * fs\n",
        "            b, a = butter(4, [low/nyq, high/nyq], btype='band')\n",
        "            return filtfilt(b, a, data)\n",
        "        whitened_bp = bandpass_filter(whitened_strain, sample_rate)\n",
        "\n",
        "        # ÊôÇÈñìËª∏\n",
        "        t_raw = np.linspace(start_time, end_time, len(raw_strain)) - trigger_time\n",
        "        t_white = np.linspace(start_time + 1, end_time - 1, len(whitened_strain)) - trigger_time\n",
        "\n",
        "        # ==========================================\n",
        "        # Âúñ‰∏ÄÔºöÂÆèËßÄÂÖ®ÊôØ (Global View - 8s)\n",
        "        # ==========================================\n",
        "        fig1, axes1 = plt.subplots(2, 2, figsize=(16, 10))\n",
        "        fig1.suptitle(\"Figure 1: Global View (Full 8s Duration)\", fontsize=16, fontweight='bold')\n",
        "\n",
        "        # Â∑¶‰∏äÔºöRaw Time\n",
        "        axes1[0, 0].plot(t_raw, raw_strain, 'gray', alpha=0.8)\n",
        "        axes1[0, 0].set_title(\"Raw Data (Time): Dominated by Low-Freq Noise\")\n",
        "        axes1[0, 0].set_ylabel(\"Strain\"); axes1[0, 0].grid(alpha=0.3)\n",
        "\n",
        "        # Âè≥‰∏äÔºöProcessed Time\n",
        "        axes1[0, 1].plot(t_white, whitened_bp, 'tab:blue')\n",
        "        axes1[0, 1].set_title(\"Processed Data (Time): Noise Flattened\")\n",
        "        axes1[0, 1].set_ylabel(\"Sigma\"); axes1[0, 1].grid(alpha=0.3)\n",
        "\n",
        "        # Â∑¶‰∏ãÔºöRaw Spec\n",
        "        axes1[1, 0].specgram(raw_strain, NFFT=256, Fs=sample_rate, noverlap=128, xextent=[t_raw[0], t_raw[-1]], cmap='inferno', scale='dB')\n",
        "        axes1[1, 0].set_title(\"Raw Spectrogram: High Intensity at Low Freq\")\n",
        "        axes1[1, 0].set_ylabel(\"Freq (Hz)\"); axes1[1, 0].set_yscale('log'); axes1[1, 0].set_ylim(20, 500)\n",
        "\n",
        "        # Âè≥‰∏ãÔºöProcessed Spec\n",
        "        f, t, Sxx = spectrogram(whitened_strain, fs=sample_rate, nperseg=128, noverlap=120)\n",
        "        axes1[1, 1].pcolormesh(t + t_white[0], f, Sxx, shading='gouraud', cmap='viridis', vmin=0, vmax=10)\n",
        "        axes1[1, 1].set_title(\"Processed Spectrogram: Signal too small to see\")\n",
        "        axes1[1, 1].set_ylabel(\"Freq (Hz)\"); axes1[1, 1].set_ylim(20, 150)\n",
        "\n",
        "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "        plt.show()\n",
        "\n",
        "        # ==========================================\n",
        "        # Âúñ‰∫åÔºöÈ°ØÂæÆËÅöÁÑ¶ (Focused View - 0.6s)\n",
        "        # ==========================================\n",
        "        fig2, axes2 = plt.subplots(2, 2, figsize=(16, 10))\n",
        "        fig2.suptitle(\"Figure 2: Focused View (Zoom-in +/- 0.3s)\", fontsize=16, fontweight='bold')\n",
        "\n",
        "        # Ë®≠ÂÆö Zoom ÁØÑÂúç\n",
        "        zoom_range = [-0.3, 0.3]\n",
        "\n",
        "        # Â∑¶‰∏äÔºöRaw Time (Zoom)\n",
        "        mask_raw = (t_raw > zoom_range[0]) & (t_raw < zoom_range[1])\n",
        "        axes2[0, 0].plot(t_raw[mask_raw], raw_strain[mask_raw], 'gray', alpha=0.8)\n",
        "        axes2[0, 0].set_title(\"Raw Data (Zoom): Still Random Noise\")\n",
        "        axes2[0, 0].set_ylabel(\"Strain\"); axes2[0, 0].grid(alpha=0.3)\n",
        "\n",
        "        # Âè≥‰∏äÔºöProcessed Time (Zoom) -> ÈÄôË£°Ë®äËôüÊúÉÁèæÂΩ¢ÔºÅ\n",
        "        mask_white = (t_white > zoom_range[0]) & (t_white < zoom_range[1])\n",
        "        axes2[0, 1].plot(t_white[mask_white], whitened_bp[mask_white], 'tab:blue', linewidth=2)\n",
        "        axes2[0, 1].set_title(\"Processed Data (Zoom): GW190521 Waveform Revealed!\")\n",
        "        axes2[0, 1].set_ylabel(\"Sigma\"); axes2[0, 1].grid(alpha=0.3)\n",
        "        # Áï´ÂÄãËôõÁ∑öÊ®ôÁ§∫‰∏≠ÂøÉÂ∞±Â•ΩÔºå‰∏çÁï´ÁÆ≠È†≠\n",
        "        axes2[0, 1].axvline(0, color='r', linestyle='--', alpha=0.5)\n",
        "\n",
        "        # Â∑¶‰∏ãÔºöRaw Spec (Zoom)\n",
        "        axes2[1, 0].specgram(raw_strain, NFFT=256, Fs=sample_rate, noverlap=128, xextent=[t_raw[0], t_raw[-1]], cmap='inferno', scale='dB')\n",
        "        axes2[1, 0].set_title(\"Raw Spectrogram (Zoom): Still Low-Freq Dominant\")\n",
        "        axes2[1, 0].set_ylabel(\"Freq (Hz)\"); axes2[1, 0].set_yscale('log'); axes2[1, 0].set_ylim(20, 500)\n",
        "        axes2[1, 0].set_xlim(zoom_range) # Âº∑Âà∂ Zoom\n",
        "\n",
        "        # Âè≥‰∏ãÔºöProcessed Spec (Zoom) -> ÈÄôË£°È†ªË≠ú‰∫ÆÈªûÊúÉÁèæÂΩ¢ÔºÅ\n",
        "        axes2[1, 1].pcolormesh(t + t_white[0], f, Sxx, shading='gouraud', cmap='viridis', vmin=0, vmax=12)\n",
        "        axes2[1, 1].set_title(\"Processed Spectrogram (Zoom): Clear Merger Signal at 60Hz\")\n",
        "        axes2[1, 1].set_ylabel(\"Freq (Hz)\"); axes2[1, 1].set_ylim(20, 150)\n",
        "        axes2[1, 1].set_xlim(zoom_range) # Âº∑Âà∂ Zoom\n",
        "\n",
        "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "        plt.show()\n",
        "\n",
        "        print(\"‚úÖ ÈõôË¶ñÂúñÁπ™Ë£ΩÂÆåÊàêÔºÅ\")\n",
        "        print(\"Âúñ‰∏ÄÂ±ïÁ§∫‰∫Ü„ÄéÂ§ßÊµ∑ÊíàÈáù„ÄèÁöÑÈõ£Â∫¶ÔºåÂúñ‰∫åÂ±ïÁ§∫‰∫Ü„ÄéÊï∏ÊìöËôïÁêÜ„ÄèÁöÑÂ®ÅÂäõ„ÄÇ\")\n",
        "\n",
        "    else:\n",
        "        print(\"‚ùå Êï∏Êìö‰∏ãËºâÂ§±Êïó„ÄÇ\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error: {e}\")"
      ],
      "metadata": {
        "id": "XVBpDCM_Z6m5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Á¨¨‰∏âÈÉ®ÂàÜÔºöÁâ©ÁêÜÂàÜÊûê (ÈÄ≤ÈöéÈ†ÖÁõÆ 1 & 2)\n",
        "\n",
        "ÂåÖÂê´Ôºö\n",
        "\n",
        "1. **ÁâõÈ†ìÂäõÂ≠∏Êì¨Âêà (Inspiral)**ÔºöË≠âÊòéÁ∞°ÂñÆÁâõÈ†ìÊ®°ÂûãÁÑ°Ê≥ïËß£ÈáãÊ≠§‰∫ã‰ª∂ÔºàÁ¥ÖÁ∑ö‰∏çÂêªÂêàÔºâ„ÄÇ\n",
        "2. **Âª£Áæ©Áõ∏Â∞çË´ñÊì¨Âêà (IMRPhenom)**Ôºö‰ΩøÁî® PyCBC ÁîüÊàêÁõ∏Â∞çË´ñÊ≥¢ÂΩ¢ÔºåÂÆåÁæéÈáçÁèæË®äËôüÔºàÁôΩÁ∑öÂêªÂêàÔºâ„ÄÇ\n",
        "3. **Ringdown ÂàÜÊûê**ÔºöÊì¨ÂêàÂêà‰ΩµÂæåÁöÑÈà¥ÊåØÊ≥¢ÂΩ¢ÔºåÊé®ÁÆóÈªëÊ¥ûÈ†ªÁéá„ÄÇ"
      ],
      "metadata": {
        "id": "5sZqShdEaCnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 3: Áâ©ÁêÜÂàÜÊûê (ÁâõÈ†ì vs Áõ∏Â∞çË´ñ + Ringdown) ===\n",
        "if 'whitened_data' not in globals():\n",
        "    print(\"‚ùå Ë´ãÂÖàÂü∑Ë°å Cell 2ÔºÅ\")\n",
        "else:\n",
        "    strain_l1 = whitened_data[0, 1].cpu().numpy()\n",
        "    plot_start = start_time + 1\n",
        "    plot_end = end_time - 1\n",
        "    time_axis = np.linspace(plot_start, plot_end, len(strain_l1))\n",
        "\n",
        "    plt.figure(figsize=(14, 12))\n",
        "\n",
        "    # --- ‰∏äÂúñÔºöInspiral & Merger ---\n",
        "    plt.subplot(2, 1, 1)\n",
        "    fs = sample_rate\n",
        "    f_vec, t_vec, Sxx = spectrogram(strain_l1, fs, nperseg=int(fs/16), noverlap=int(fs/16*0.95))\n",
        "    plt.pcolormesh(t_vec + plot_start, f_vec, Sxx, shading='gouraud', cmap='viridis', vmin=0, vmax=15)\n",
        "\n",
        "    # ÁâõÈ†ìÂäõÂ≠∏ (Á¥ÖËôõÁ∑ö)\n",
        "    G, c, M_solar = 6.674e-11, 3e8, 1.989e30\n",
        "    m1, m2 = 85 * M_solar, 66 * M_solar\n",
        "    chirp_mass = (m1 * m2)**(3/5) / (m1 + m2)**(1/5)\n",
        "    def newtonian_freq(t, tc):\n",
        "        tau = tc - t\n",
        "        with np.errstate(invalid='ignore'):\n",
        "            return (c**3)/(8*np.pi*G*chirp_mass) * ((5*G*chirp_mass)/(c**3*tau))**(3/8)\n",
        "\n",
        "    t_model = np.linspace(trigger_time - 1.5, trigger_time, 1000)\n",
        "    plt.plot(t_model, newtonian_freq(t_model, trigger_time+0.02), 'r--', linewidth=3, label='Newtonian')\n",
        "\n",
        "    # Âª£Áæ©Áõ∏Â∞çË´ñ (ÁôΩÂØ¶Á∑ö)\n",
        "    hp, _ = get_td_waveform(approximant=\"IMRPhenomXPHM\", mass1=95, mass2=69, spin1z=0.7, spin2z=0.7, delta_t=1.0/fs, f_lower=20)\n",
        "    hp.resize(len(hp))\n",
        "    rel_time = hp.sample_times.numpy() + (trigger_time - hp.sample_times[-1])\n",
        "    plt.plot(rel_time, hp.numpy() * 400 * 1e19 + 60, 'w-', linewidth=2, alpha=0.9, label='GR Waveform')\n",
        "\n",
        "    plt.yscale('log'); plt.ylim(20, 150); plt.xlim(trigger_time-0.5, trigger_time+0.2)\n",
        "    plt.title(\"Part 1: Newtonian vs GR\", fontsize=14, fontweight='bold'); plt.legend(loc='upper left')\n",
        "\n",
        "    # --- ‰∏ãÂúñÔºöRingdown ---\n",
        "    plt.subplot(2, 1, 2)\n",
        "    peak_idx = np.argmax(np.abs(strain_l1[(time_axis > trigger_time-0.1) & (time_axis < trigger_time+0.1)]))\n",
        "    global_peak_idx = np.where((time_axis > trigger_time-0.1))[0][0] + peak_idx\n",
        "\n",
        "    start_fit = global_peak_idx + int(0.003 * fs)\n",
        "    end_fit = global_peak_idx + int(0.05 * fs)\n",
        "    t_ring = time_axis[start_fit:end_fit]\n",
        "    h_ring = strain_l1[start_fit:end_fit]\n",
        "\n",
        "    def ringdown_model(t, A, tau, f, phi):\n",
        "        return A * np.exp(-(t-t[0])/tau) * np.cos(2*np.pi*f*(t-t[0]) + phi)\n",
        "\n",
        "    try:\n",
        "        popt, _ = curve_fit(ringdown_model, t_ring, h_ring, p0=[np.max(h_ring), 0.01, 65, 0])\n",
        "        plt.plot(time_axis, strain_l1, 'k-', alpha=0.3)\n",
        "        plt.plot(t_ring, ringdown_model(t_ring, *popt), 'r-', linewidth=2.5, label=f'Fit (f={popt[2]:.1f}Hz)')\n",
        "        plt.xlim(trigger_time-0.05, trigger_time+0.1)\n",
        "        plt.title(f\"Part 2: Ringdown (f={popt[2]:.1f} Hz)\", fontsize=14, fontweight='bold'); plt.legend()\n",
        "    except:\n",
        "        print(\"Ringdown fit failed\")\n",
        "\n",
        "    plt.tight_layout(); plt.show()"
      ],
      "metadata": {
        "id": "qY5SlFTiaKOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Á¨¨ÂõõÈÉ®ÂàÜÔºöÊ∑±Â∫¶Â≠∏ÁøíË®äËôüËæ®Ë≠ò (ÈÄ≤ÈöéÈ†ÖÁõÆ 3)\n",
        "\n",
        "‰ΩøÁî® ResNet-18 ÈÄ≤Ë°å„ÄåÊúâÁõ£Áù£Â≠∏Áøí„Äç„ÄÇ\n",
        "\n",
        "* **Êï∏ÊìöÂ¢ûÂº∑**ÔºöÂà©Áî® `IMRPhenomXPHM` ÁîüÊàêÊ®°Êì¨Ê≥¢ÂΩ¢Ôºå‰∏¶Ê∑∑ÂêàÁúüÂØ¶ÈõúË®äÁâπÂæµ„ÄÇ\n",
        "* **ÂéªÂô™ËôïÁêÜ**ÔºöÂØ¶ÊñΩ Notch Filter (60Hz) ÁßªÈô§ÈõªÊ∫êÁ∑öÂπ≤Êìæ (PhysRevLett.125.101102ÊèêÂà∞) „ÄÇ\n",
        "* **ÂØ¶Êà∞È©óË≠â**ÔºöÂ∞áÊ®°ÂûãÊáâÁî®ÊñºÁúüÂØ¶ GW190521 Êï∏Êìö„ÄÇ"
      ],
      "metadata": {
        "id": "dAGwQ1azaSn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 4 (ÊúÄÁµÇÁúüÂØ¶Èõ£Â∫¶Áâà): Ê®°Êì¨ÈÅôÈÅ†ÂæÆÂº±Ë®äËôü (Low SNR) ===\n",
        "import concurrent.futures\n",
        "from tqdm.auto import tqdm\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from pycbc.waveform import get_td_waveform\n",
        "from scipy.signal import spectrogram, iirnotch, filtfilt\n",
        "\n",
        "DATA_FILE = \"gw190521_focused_dataset.pt\"\n",
        "NUM_SAMPLES = 12000 # Ê®£Êú¨Êï∏\n",
        "SAMPLE_RATE = 2048\n",
        "DURATION = 0.5 # ‰øùÊåÅ 0.5s ËÅöÁÑ¶Á™óÂè£ÔºåËÆì 0.1s ÁöÑË®äËôüÁâπÂæµÂ§†Â§ß\n",
        "\n",
        "def apply_notch(data, fs=2048):\n",
        "    data = np.nan_to_num(data)\n",
        "    for f in [60, 120, 180]:\n",
        "        b, a = iirnotch(f, 30, fs)\n",
        "        data = filtfilt(b, a, data)\n",
        "    return np.nan_to_num(data)\n",
        "\n",
        "def get_ai_spec(strain, fs=2048):\n",
        "    # nperseg=128 ÈÅ©ÂêàÁü≠Á™óÂè£ÔºåÊôÇÈñìËß£ÊûêÂ∫¶ËºÉÈ´ò\n",
        "    f, t, Sxx = spectrogram(strain, fs=fs, nperseg=128, noverlap=120)\n",
        "\n",
        "    # È†ªÁéáÂè™Âèñ 20-150Hz (ÈªëÊ¥ûÂêà‰Ωµ‰∏ªË¶ÅÈ†ªÊÆµÔºåÂéªÈô§ÈùûÂøÖË¶ÅÁöÑÈ´òÈ†ªÁ©∫ÁôΩ)\n",
        "    mask = (f >= 20) & (f <= 150)\n",
        "    spec = np.log(Sxx[mask, :] + 1e-10)\n",
        "    # Ê®ôÊ∫ñÂåñÔºöÈÄôË£°ÁöÑ clip ÁØÑÂúçÂèØ‰ª•Á®çÂæÆÂØ¨‰∏ÄÈªûÔºå‰øùÁïô‰∏Ä‰∫õÈõúË®äÁ¥∞ÁØÄ\n",
        "    spec = np.clip(spec, np.mean(spec)-2.5*np.std(spec), np.mean(spec)+3.5*np.std(spec))\n",
        "    return (spec - np.min(spec)) / (np.max(spec) - np.min(spec) + 1e-8)\n",
        "\n",
        "def worker(i):\n",
        "    np.random.seed(int.from_bytes(os.urandom(4), 'little'))\n",
        "\n",
        "    # 1. Áî¢ÁîüÁ∏ΩÈï∑Â∫¶ (ÁîüÊàêÈï∑‰∏ÄÈªû‰ª•ÂÖçÈÇäÁ∑£ÊïàÊáâ)\n",
        "    N_gen = int(SAMPLE_RATE * 2.0)\n",
        "    # ËÉåÊôØÈõúË®äÂº∑Â∫¶Ë®≠ÁÇ∫ 1.0 (Ê®ôÊ∫ñÈ´òÊñØÁôΩÈõúË®ä)\n",
        "    noise = np.random.normal(0, 1.0, N_gen)\n",
        "\n",
        "    # 2. ÂÆöÁæ©ÊúÄÁµÇÊì∑ÂèñÁöÑË¶ñÁ™ó‰∏≠ÂøÉ\n",
        "    center_idx = N_gen // 2\n",
        "    half_window = int(SAMPLE_RATE * DURATION / 2)\n",
        "\n",
        "    if i % 2 == 0: # Signal (Ê®ôÁ±§ 1)\n",
        "        # ÁîüÊàêÊ≥¢ÂΩ¢ (È†êË®≠Ë∑ùÈõ¢ 1 Mpc)\n",
        "        hp, _ = get_td_waveform(approximant=\"IMRPhenomXPHM\",\n",
        "                                mass1=np.random.uniform(60, 100), # ÈáùÂ∞ç GW190521 ÁöÑË≥™ÈáèÁØÑÂúç\n",
        "                                mass2=np.random.uniform(40, 80),\n",
        "                                delta_t=1.0/SAMPLE_RATE,\n",
        "                                f_lower=20)\n",
        "        hp.resize(len(hp))\n",
        "        sig_raw = hp.numpy()\n",
        "\n",
        "        # ÊâæÂà∞Ë®äËôüÂ≥∞ÂÄº (Merger)\n",
        "        peak_idx_sig = np.argmax(np.abs(sig_raw))\n",
        "\n",
        "        # Â∞áË®äËôüÂ≥∞ÂÄºÂ∞çÈΩäÂà∞Âô™ËÅ≤‰∏≠ÂøÉ (Center Alignment)\n",
        "        # ‰∏¶Âä†ÂÖ•‰∏ÄÈªûÈªûÈö®Ê©üÊäñÂãï (Jitter +/- 0.05s)\n",
        "        jitter = np.random.randint(-int(0.05*SAMPLE_RATE), int(0.05*SAMPLE_RATE))\n",
        "        place_idx = center_idx + jitter\n",
        "\n",
        "        # Ë®àÁÆóÁñäÂä†‰ΩçÁΩÆ\n",
        "        start_sig = place_idx - peak_idx_sig\n",
        "        end_sig = start_sig + len(sig_raw)\n",
        "\n",
        "        # ÈÇäÁïåÊ™¢Êü•ËàáÁñäÂä†\n",
        "        valid_start = max(0, start_sig)\n",
        "        valid_end = min(N_gen, end_sig)\n",
        "\n",
        "        sig_offset = valid_start - start_sig\n",
        "        sig_len = valid_end - valid_start\n",
        "\n",
        "        if sig_len > 0:\n",
        "            # === ÈóúÈçµ‰øÆÊîπÔºöÊ®°Êì¨ÁúüÂØ¶ÂæÆÂº±Ë®äËôü ===\n",
        "            # Ë®≠ÂÆö amp_scale Âú® 0.05 ~ 0.2 ‰πãÈñì (Ê•µ‰Ωé SNR)\n",
        "            amp_scale = np.random.uniform(0.05, 0.2)\n",
        "\n",
        "            # ÁñäÂä†Ë®äËôü\n",
        "            noise[valid_start:valid_end] += sig_raw[sig_offset : sig_offset+sig_len] * 1e19 * amp_scale\n",
        "\n",
        "        # Êì∑Âèñ‰∏≠ÂøÉ 0.5s\n",
        "        final_data = noise[center_idx-half_window : center_idx+half_window]\n",
        "        return get_ai_spec(apply_notch(final_data)), 1.0\n",
        "\n",
        "    else: # Noise (Ê®ôÁ±§ 0)\n",
        "        # Á¥îÈõúË®ä‰πüÂèñ‰∏≠ÂøÉ\n",
        "        final_data = noise[center_idx-half_window : center_idx+half_window]\n",
        "        return get_ai_spec(apply_notch(final_data)), 0.0\n",
        "\n",
        "# Âº∑Âà∂Âà™Èô§ËàäÊ™î‰∏¶ÈáçÊñ∞ÁîüÊàê\n",
        "if os.path.exists(DATA_FILE):\n",
        "    os.remove(DATA_FILE)\n",
        "\n",
        "print(f\"üöÄ ÁîüÊàê„ÄåÁúüÂØ¶Èõ£Â∫¶„ÄçÊï∏Êìö (Window={DURATION}s, Amp=0.05~0.2)...\")\n",
        "with concurrent.futures.ProcessPoolExecutor() as ex:\n",
        "    results = list(tqdm(ex.map(worker, range(NUM_SAMPLES)), total=NUM_SAMPLES))\n",
        "\n",
        "data, labels = zip(*results)\n",
        "data_tensor = torch.tensor(np.array(data)).unsqueeze(1).float()\n",
        "labels_tensor = torch.tensor(np.array(labels)).unsqueeze(1).float()\n",
        "torch.save({\"data\": data_tensor, \"labels\": labels_tensor}, DATA_FILE)\n",
        "print(\"‚úÖ ÁúüÂØ¶Èõ£Â∫¶Êï∏ÊìöÁîüÊàêÂÆåÁï¢ÔºÅË´ãÈáçÊñ∞Âü∑Ë°å Cell 5 ÈÄ≤Ë°åË®ìÁ∑¥„ÄÇ\")"
      ],
      "metadata": {
        "id": "WW72Lz3saYuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 5 (ÊúÄÁµÇ‰øÆÂæ©Áâà): Ë®ìÁ∑¥ + Áï´Âúñ + Ëá™ÂãïÂ≠òÊ™î ===\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Á°¨È´îÂä†ÈÄü\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "DATA_FILE = \"gw190521_focused_dataset.pt\"\n",
        "\n",
        "# --- 1. ÂÆöÁæ© Dataset ---\n",
        "class WaveDataset(Dataset):\n",
        "    def __init__(self, tensors, labels, transform=None):\n",
        "        self.tensors = tensors\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.tensors[index]\n",
        "        y = self.labels[index]\n",
        "        if self.transform:\n",
        "            x = self.transform(x) # Resize & Augment\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tensors)\n",
        "\n",
        "if not os.path.exists(DATA_FILE):\n",
        "    print(\"‚ùå ÊïëÂëΩÂïäÔºåÊâæ‰∏çÂà∞Êï∏ÊìöÊ™îÔºÅË´ãÂõûÂéªË∑ë Cell 4ÔºÅ\")\n",
        "else:\n",
        "    # --- 2. Ê∫ñÂÇôÊï∏Êìö ---\n",
        "    saved = torch.load(DATA_FILE)\n",
        "    full_data = saved[\"data\"]\n",
        "    full_labels = saved[\"labels\"]\n",
        "\n",
        "    # Ë®ìÁ∑¥ÈõÜÔºöÂä†ÈªûÊñô (ÁøªËΩâ„ÄÅÂπ≥Áßª) Èò≤Ê≠¢Ê≠ªË®ò\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomApply([transforms.RandomAffine(degrees=0, translate=(0.05, 0.05))], p=0.3),\n",
        "    ])\n",
        "    # È©óË≠âÈõÜÔºö‰πæÊ∑®ÁöÑÔºåÂè™Ë≤†Ë≤¨Á∏ÆÊîæ\n",
        "    val_transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224))\n",
        "    ])\n",
        "\n",
        "    # 80% Ë®ìÁ∑¥, 20% È©óË≠â\n",
        "    total_len = len(full_data)\n",
        "    train_len = int(0.8 * total_len)\n",
        "    generator = torch.Generator().manual_seed(42)\n",
        "    perm = torch.randperm(total_len, generator=generator)\n",
        "\n",
        "    train_ds = WaveDataset(full_data[perm[:train_len]], full_labels[perm[:train_len]], transform=train_transform)\n",
        "    val_ds = WaveDataset(full_data[perm[train_len:]], full_labels[perm[train_len:]], transform=val_transform)\n",
        "\n",
        "    train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "    val_dl = DataLoader(val_ds, batch_size=32)\n",
        "\n",
        "    # --- 3. Âª∫Á´ãÊ®°Âûã (EfficientNet-B0) ---\n",
        "    print(\"üõ†Ô∏è Ê≠£Âú®ÁµÑË£ù EfficientNet-B0 (Â∞àÁÇ∫ÂæÆÂº±Ë®äËôüÂÑ™Âåñ)...\")\n",
        "    # ÂòóË©¶ËºâÂÖ• EfficientNetÔºåÂ¶ÇÊûúÁâàÊú¨Â§™ËàäÊ≤íÊúâÂâáÈÄÄÂõû ResNet\n",
        "    try:\n",
        "        model = models.efficientnet_b0(weights=None)\n",
        "        first_conv = model.features[0][0]\n",
        "        model.features[0][0] = nn.Conv2d(1, first_conv.out_channels,\n",
        "                                         kernel_size=first_conv.kernel_size, stride=first_conv.stride,\n",
        "                                         padding=first_conv.padding, bias=False)\n",
        "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, 1)\n",
        "    except:\n",
        "        print(\"‚ö†Ô∏è EfficientNet ËºâÂÖ•Â§±ÊïóÔºåÂàáÊèõÂõû ResNet18...\")\n",
        "        model = models.resnet18(weights=None)\n",
        "        model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        model.fc = nn.Linear(model.fc.in_features, 1)\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    # --- 4. Ë®ìÁ∑¥Ë®≠ÂÆö ---\n",
        "    opt = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "    crit = nn.BCEWithLogitsLoss()\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(opt, mode='max', factor=0.5, patience=2)\n",
        "\n",
        "    # --- 5. ÈñãÂßãË®ìÁ∑¥ ---\n",
        "    epochs = 10 # ÈõñÁÑ∂Ë®≠ 10Ôºå‰ΩÜÊàëÂÄëÊúÉËá™ÂãïÂ≠òÊúÄÂ•ΩÁöÑ\n",
        "    hist = {'train':[], 'val':[], 'acc':[]}\n",
        "    best_acc = 0.0\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    print(f\"üöÄ ‰ªªÂãôÈñãÂßãÔºöË®ìÁ∑¥ {epochs} Ëº™...\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        run_loss = 0\n",
        "        for x, y in train_dl:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            opt.zero_grad()\n",
        "            out = model(x)\n",
        "            loss = crit(out, y)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            run_loss += loss.item()\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for x, y in val_dl:\n",
        "                x, y = x.to(device), y.to(device)\n",
        "                out = model(x)\n",
        "                val_loss += crit(out, y).item()\n",
        "                preds = (torch.sigmoid(out) > 0.5).float()\n",
        "                correct += (preds == y).sum().item()\n",
        "\n",
        "        acc = correct / len(val_ds)\n",
        "        epoch_train_loss = run_loss / len(train_dl)\n",
        "        epoch_val_loss = val_loss / len(val_dl)\n",
        "\n",
        "        hist['train'].append(epoch_train_loss)\n",
        "        hist['val'].append(epoch_val_loss)\n",
        "        hist['acc'].append(acc)\n",
        "        scheduler.step(acc)\n",
        "\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            print(f\"Epoch {epoch+1:02d} | Train: {epoch_train_loss:.4f} | Val: {epoch_val_loss:.4f} | Acc: {acc:.2%} üü¢ (Êñ∞È´ò!)\")\n",
        "        else:\n",
        "            print(f\"Epoch {epoch+1:02d} | Train: {epoch_train_loss:.4f} | Val: {epoch_val_loss:.4f} | Acc: {acc:.2%}\")\n",
        "\n",
        "    print(f\"\\nüèÜ Ë®ìÁ∑¥ÁµêÊùüÔºÅÊúÄ‰Ω≥Ê∫ñÁ¢∫Áéá: {best_acc:.2%}\")\n",
        "    model.load_state_dict(best_model_wts) # <--- Ëá™ÂãïËºâÂÖ•ÊúÄÂº∑Ê®°Âûã (Epoch 5)\n",
        "\n",
        "    # --- 6. ÁîüÊàê PPT Á¥†Êùê (Ëá™ÂãïÂ≠òÊ™î) ---\n",
        "    print(\"\\nüé® Ê≠£Âú®Áπ™Ë£Ω PPT Á¥†Êùê...\")\n",
        "\n",
        "    # Âúñ‰∏ÄÔºöË®ìÁ∑¥Êõ≤Á∑ö\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(hist['train'], label='Train Loss')\n",
        "    plt.plot(hist['val'], label='Val Loss')\n",
        "    plt.title(\"Loss Curve (Training Process)\")\n",
        "    plt.xlabel(\"Epoch\"); plt.legend(); plt.grid(True)\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(hist['acc'], color='green', marker='o')\n",
        "    plt.title(f\"Validation Accuracy (Best: {best_acc:.1%})\")\n",
        "    plt.xlabel(\"Epoch\"); plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('training_curve.png') # <--- Â≠òÊ™î\n",
        "    plt.show()\n",
        "    print(\"‚úÖ Â∑≤ÂÑ≤Â≠ò 'training_curve.png'\")\n",
        "\n",
        "    # Âúñ‰∫åÔºöÈ†êÊ∏¨ÂØ¶‰æã (ÈÄôÂÄãÊúÄÈáçË¶ÅÔºÅ)\n",
        "    model.eval()\n",
        "    x_sample, y_sample = next(iter(val_dl))\n",
        "    x_sample = x_sample[:5].to(device)\n",
        "    y_sample = y_sample[:5].to(device)\n",
        "    with torch.no_grad():\n",
        "        out = model(x_sample)\n",
        "        probs = torch.sigmoid(out).cpu().numpy().flatten()\n",
        "\n",
        "    plt.figure(figsize=(15, 3))\n",
        "    for i in range(5):\n",
        "        plt.subplot(1, 5, i+1)\n",
        "        img = x_sample[i].cpu().squeeze().numpy()\n",
        "        plt.imshow(img, origin='lower', aspect='auto', cmap='magma')\n",
        "\n",
        "        is_signal = y_sample[i].item() == 1.0\n",
        "        ai_prob = probs[i]\n",
        "\n",
        "        # Ê®ôÈ°åÈ°èËâ≤ÔºöÁ∂†Ëâ≤‰ª£Ë°®Á≠îÂ∞çÔºåÁ¥ÖËâ≤‰ª£Ë°®Á≠îÈåØ\n",
        "        title_color = 'green' if (ai_prob > 0.5) == is_signal else 'red'\n",
        "\n",
        "        plt.title(f\"Truth: {'Signal' if is_signal else 'Noise'}\\nAI: {ai_prob:.2%} conf\",\n",
        "                  color=title_color, fontsize=10, fontweight='bold')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('prediction_result.png') # <--- Â≠òÊ™î\n",
        "    plt.show()\n",
        "    print(\"‚úÖ Â∑≤ÂÑ≤Â≠ò 'prediction_result.png'\")"
      ],
      "metadata": {
        "id": "-EMv86Z2h5qR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 6: ÊúÄÁµÇ AI È©óÊî∂ (Signal vs Noise) ===\n",
        "# Á¢∫‰øù‰ΩøÁî®ËàáË®ìÁ∑¥‰∏ÄËá¥ÁöÑÈ†êËôïÁêÜ\n",
        "def get_ai_spec(strain, fs=2048):\n",
        "    f, t, Sxx = spectrogram(strain, fs=fs, nperseg=256, noverlap=240)\n",
        "    mask = (f >= 20) & (f <= 300)\n",
        "    spec = np.log(Sxx[mask, :] + 1e-10)\n",
        "    spec = np.clip(spec, np.mean(spec)-2.5*np.std(spec), np.mean(spec)+2.5*np.std(spec))\n",
        "    return (spec - np.min(spec)) / (np.max(spec) - np.min(spec) + 1e-8), t, f[mask]\n",
        "\n",
        "# ÊäìÂèñÁúüÂØ¶Êï∏Êìö\n",
        "idx_sig = int(5.0 * sample_rate)\n",
        "idx_noise = int(2.0 * sample_rate)\n",
        "hw = int(0.5 * sample_rate)\n",
        "\n",
        "sig_data = whitened_data[0, 1, idx_sig-hw:idx_sig+hw].cpu().numpy()\n",
        "noise_data = whitened_data[0, 1, idx_noise-hw:idx_noise+hw].cpu().numpy()\n",
        "\n",
        "# È†êÊ∏¨\n",
        "model.eval()\n",
        "spec_sig, _, f_axis = get_ai_spec(sig_data)\n",
        "spec_noise, _, _ = get_ai_spec(noise_data)\n",
        "\n",
        "with torch.no_grad():\n",
        "    score_sig = torch.sigmoid(model(torch.tensor(spec_sig).unsqueeze(0).unsqueeze(0).float().to(device))).item()\n",
        "    score_noise = torch.sigmoid(model(torch.tensor(spec_noise).unsqueeze(0).unsqueeze(0).float().to(device))).item()\n",
        "\n",
        "# Áπ™Âúñ\n",
        "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
        "ax[0].imshow(spec_sig, origin='lower', aspect='auto', cmap='viridis', extent=[-0.5, 0.5, f_axis[0], f_axis[-1]])\n",
        "ax[0].set_title(f\"Target: Signal\\nConf: {score_sig:.4f}\", color='green', fontweight='bold')\n",
        "ax[0].axvline(0, color='r', linestyle='--')\n",
        "\n",
        "ax[1].imshow(spec_noise, origin='lower', aspect='auto', cmap='viridis', extent=[-0.5, 0.5, f_axis[0], f_axis[-1]])\n",
        "ax[1].set_title(f\"Control: Noise\\nConf: {score_noise:.4f}\", color='black', fontweight='bold')\n",
        "\n",
        "plt.show()\n",
        "print(f\"üöÄ AI Âà§Êñ∑ÔºöË®äËôü‰ø°ÂøÉÂ∫¶ {score_sig:.2%} | ÈõúË®äË™§Âà§Áéá {score_noise:.2%}\")"
      ],
      "metadata": {
        "id": "SJnqc1EAjsLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 7 (‰øÆÊ≠£Áâà): Ë£Ω‰ΩúÊ≥¢ÂΩ¢ÊéÉÊèèÂãïÁï´‰∏¶Â≠òÊ™î (MP4/GIF) ===\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from matplotlib import rc\n",
        "import numpy as np\n",
        "\n",
        "# 1. Ëß£Èô§ÂãïÁï´Â§ßÂ∞èÈôêÂà∂ (Ë®≠ÁÇ∫ 100MB)\n",
        "plt.rcParams['animation.embed_limit'] = 100.0\n",
        "# Ë®≠ÂÆö ffmpeg (Áî®ÊñºÁîüÊàê MP4)\n",
        "rc('animation', html='jshtml')\n",
        "\n",
        "print(\"Ê≠£Âú®Ë£Ω‰Ωú‰∏¶ÂÑ≤Â≠òÂãïÁï´ÔºåË´ãÁ®çÂÄô...\")\n",
        "\n",
        "# 2. Ê∫ñÂÇôÊï∏Êìö\n",
        "# ÁÇ∫‰∫ÜÈÅøÂÖçÊ™îÊ°àÈÅéÂ§ßÔºåÊàëÂÄëÂè™ÂèñÊúÄÁ≤æÂΩ©ÁöÑ 1 ÁßíÈêò (Trigger ÂâçÂæå 0.5s)\n",
        "center_idx = int(5.0 * sample_rate)\n",
        "window = int(0.5 * sample_rate)\n",
        "data_anim = whitened_data[0, 1, center_idx-window : center_idx+window].cpu().numpy()\n",
        "\n",
        "# Á∞°ÂñÆÊøæÊ≥¢ËÆìÁ∑öÊ¢ùÂ•ΩÁúãÈªû\n",
        "def apply_notch_anim(data, fs=2048):\n",
        "    from scipy.signal import iirnotch, filtfilt\n",
        "    data = np.nan_to_num(data)\n",
        "    for f in [60, 120, 180]:\n",
        "        b, a = iirnotch(f, 30, fs)\n",
        "        data = filtfilt(b, a, data)\n",
        "    return data\n",
        "\n",
        "data_anim = apply_notch_anim(data_anim, sample_rate)\n",
        "t_anim = np.linspace(-0.5, 0.5, len(data_anim))\n",
        "\n",
        "# 3. Ë®≠ÂÆöÁï´Â∏É (Ë™øÊï¥ figsize Âíå DPI ‰ª•ÊéßÂà∂Ê™îÊ°àÂ§ßÂ∞è)\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 6), dpi=100, sharex=True)\n",
        "\n",
        "# ‰∏äÂúñÔºöÊ≥¢ÂΩ¢\n",
        "line, = ax1.plot([], [], 'w-', linewidth=1.5)\n",
        "ax1.set_xlim(-0.5, 0.2)\n",
        "ax1.set_ylim(-6, 6)\n",
        "ax1.set_facecolor('black')\n",
        "ax1.set_ylabel('Strain', color='white')\n",
        "ax1.set_title('GW190521 Merger Event', fontsize=14)\n",
        "ax1.grid(True, alpha=0.3, color='gray')\n",
        "\n",
        "# ‰∏ãÂúñÔºöÈ†ªË≠úÂúñ\n",
        "from scipy.signal import spectrogram\n",
        "f, t, Sxx = spectrogram(data_anim, fs=sample_rate, nperseg=128, noverlap=120)\n",
        "t = t - 0.5 # Ê†°Ê≠£ÊôÇÈñì\n",
        "mesh = ax2.pcolormesh(t, f, Sxx, shading='gouraud', cmap='viridis', vmin=0, vmax=10)\n",
        "ax2.set_ylabel('Frequency (Hz)')\n",
        "ax2.set_xlabel('Time (s)')\n",
        "ax2.set_ylim(20, 150)\n",
        "ax2.set_facecolor('black')\n",
        "\n",
        "# ÊéÉÊèèÁ∑ö\n",
        "vline1 = ax1.axvline(x=-0.5, color='r', linestyle='--')\n",
        "vline2 = ax2.axvline(x=-0.5, color='r', linestyle='--')\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# 4. Êõ¥Êñ∞ÂáΩÊï∏\n",
        "def update(frame):\n",
        "    current_time = t_anim[frame]\n",
        "    # Êõ¥Êñ∞Ê≥¢ÂΩ¢\n",
        "    line.set_data(t_anim[:frame], data_anim[:frame])\n",
        "    # Êõ¥Êñ∞ÊéÉÊèèÁ∑ö\n",
        "    vline1.set_xdata([current_time])\n",
        "    vline2.set_xdata([current_time])\n",
        "    return line, vline1, vline2\n",
        "\n",
        "# 5. ÁîüÊàêÂãïÁï´ (Èôç‰ΩéÊé°Ê®£Áéá Step=4 ‰ª•Á∏ÆÂ∞èÈ´îÁ©ç)\n",
        "step = 4\n",
        "frames = range(0, len(t_anim), step)\n",
        "ani = animation.FuncAnimation(fig, update, frames=frames, interval=20, blit=True)\n",
        "\n",
        "# === ÈóúÈçµ‰øÆÊîπÔºöÂ≠òÊàêÁç®Á´ãÊ™îÊ°à ===\n",
        "# ÂÑ≤Â≠ò MP4 (PPT È¶ñÈÅ∏ÔºåÁï´Ë≥™Â•ΩÈ´îÁ©çÂ∞è)\n",
        "print(\"Ê≠£Âú®ÂÑ≤Â≠òÁÇ∫ gw190521.mp4 ...\")\n",
        "ani.save('gw190521.mp4', writer='ffmpeg', fps=30)\n",
        "\n",
        "# ÂÑ≤Â≠ò GIF (ÂÇôÁî®ÔºåÁõ∏ÂÆπÊÄßÈ´ò‰ΩÜÈ´îÁ©çÂ§ß)\n",
        "print(\"Ê≠£Âú®ÂÑ≤Â≠òÁÇ∫ gw190521.gif ...\")\n",
        "ani.save('gw190521.gif', writer='pillow', fps=15)\n",
        "\n",
        "plt.close()\n",
        "print(\"‚úÖ ÂãïÁï´Ë£Ω‰ΩúÂÆåÊàêÔºÅ\")\n",
        "print(\"üì• Ë´ãÊü•ÁúãÂ∑¶ÂÅ¥Ê™îÊ°àÊ¨Ñ (Files)Ôºå‰∏ãËºâ 'gw190521.mp4' Êàñ 'gw190521.gif' ÊîæÂÖ•ÊäïÂΩ±Áâá„ÄÇ\")"
      ],
      "metadata": {
        "id": "B7RKsRvhox0L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}