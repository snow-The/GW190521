{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "L4",
      "authorship_tag": "ABX9TyNrlIeLztoRdpBiqvxWXnWs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snow-The/GW190521/blob/main/homework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# é‡åŠ›æ³¢ GW190521 æ•¸æ“šåˆ†æèˆ‡ AI è¾¨è­˜å°ˆé¡Œå ±å‘Š\n",
        "\n",
        "æœ¬å°ˆé¡Œæ—¨åœ¨åˆ©ç”¨ä¿¡è™Ÿè™•ç†èˆ‡æ·±åº¦å­¸ç¿’æŠ€è¡“ï¼Œåˆ†æä¸­ç­‰è³ªé‡é»‘æ´åˆä½µäº‹ä»¶ GW190521ã€‚\n",
        "å…§å®¹æ¶µè“‹ï¼š\n",
        "\n",
        "1. **åŸºæœ¬é …ç›®**ï¼šæ•¸æ“šä¸‹è¼‰ã€ç™½åŒ– (Whitening)ã€é »è­œåœ–ç¹ªè£½ã€‚\n",
        "2. **é€²éšé …ç›® (ç‰©ç†)**ï¼šç‰›é “åŠ›å­¸æ“¬åˆå¤±æ•ˆé©—è­‰ã€Ringdown éˆ´æŒ¯åˆ†æã€å»£ç¾©ç›¸å°è«–æ³¢å½¢æ“¬åˆã€‚\n",
        "3. **é€²éšé …ç›® (AI)**ï¼šåŸºæ–¼ ResNet çš„æ·±åº¦å­¸ç¿’è¨Šè™Ÿè¾¨è­˜ (å« Notch Filter å»å™ªèˆ‡æ¨¡æ“¬æ•¸æ“šå¢å¼·)ã€‚"
      ],
      "metadata": {
        "id": "VprDKo26Zkdp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ç¬¬ä¸€éƒ¨åˆ†ï¼šç’°å¢ƒå®‰è£èˆ‡è¨­ç½®\n",
        "\n",
        "å®‰è£é‡åŠ›æ³¢åˆ†æå¿…è¦çš„ Python å¥—ä»¶ (`gwpy`, `ml4gw`, `pycbc` ç­‰)ã€‚"
      ],
      "metadata": {
        "id": "8uhnYYBPZovp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A86Icjg3Mk0D",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# === Cell 1: ç’°å¢ƒå®‰è£èˆ‡è¨­ç½® ===\n",
        "!pip install \"ml4gw>=0.7.10\" \"gwpy>=3.0\" \"h5py>=3.12\" \"torchmetrics>=1.6\" \"lightning>=2.4.0\" \"rich>=10.2.2,<14.0\" \"pycbc\" \"lalsuite\"\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from gwpy.timeseries import TimeSeries\n",
        "from ml4gw.transforms import Whiten, SpectralDensity\n",
        "from scipy.signal import iirnotch, filtfilt, spectrogram, butter\n",
        "from scipy.optimize import curve_fit\n",
        "from pycbc.waveform import get_td_waveform\n",
        "import os\n",
        "\n",
        "# è¨­å®šé‹ç®—è¨­å‚™\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ç¬¬äºŒéƒ¨åˆ†ï¼šæ•¸æ“šç²å–èˆ‡é è™•ç† (åŸºæœ¬é …ç›®)\n",
        "\n",
        "ä¸‹è¼‰ GW190521 ï¼ˆV4ï¼‰åŸå§‹æ•¸æ“šï¼ŒåŸ·è¡Œç™½åŒ– (Whitening) ä»¥å£“åˆ¶ä½é »é›œè¨Šï¼Œä¸¦ç¹ªè£½åˆæ­¥é »è­œåœ–ã€‚"
      ],
      "metadata": {
        "id": "0ZueNUL4ZwC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 2 (æœ€çµ‚å®Œç¾ç‰ˆ): æ•¸æ“šä¸‹è¼‰ã€ç™½åŒ–èˆ‡ã€Œå®è§€ vs å¾®è§€ã€é›™è¦–åœ– ===\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from gwpy.timeseries import TimeSeries\n",
        "from ml4gw.transforms import Whiten, SpectralDensity\n",
        "from scipy.signal import spectrogram, butter, filtfilt\n",
        "\n",
        "# 1. åƒæ•¸è¨­å®š\n",
        "trigger_time = 1242442967.4\n",
        "sample_rate = 2048\n",
        "start_time = trigger_time - 6\n",
        "end_time = trigger_time + 2\n",
        "psd_start = start_time - 64\n",
        "psd_end = start_time\n",
        "ifos = [\"H1\", \"L1\"]\n",
        "\n",
        "# 2. ä¸‹è¼‰å‡½æ•¸\n",
        "def get_data(detectors, start, end):\n",
        "    tensors = []\n",
        "    print(f\"Downloading data for {start} to {end}...\")\n",
        "    for det in detectors:\n",
        "        try:\n",
        "            ts = TimeSeries.fetch_open_data(det, start, end, verbose=False)\n",
        "            ts = ts.resample(sample_rate)\n",
        "            if np.isnan(ts.value).any():\n",
        "                ts.value = np.nan_to_num(ts.value)\n",
        "            tensors.append(torch.from_numpy(ts.value.copy()).float())\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to download {det}: {e}\")\n",
        "            return None\n",
        "    return torch.stack(tensors).to(device)\n",
        "\n",
        "# 3. åŸ·è¡Œè™•ç†\n",
        "try:\n",
        "    data_tensor = get_data(ifos, start_time, end_time)\n",
        "    psd_tensor = get_data(ifos, psd_start, psd_end)\n",
        "\n",
        "    if data_tensor is not None and psd_tensor is not None:\n",
        "        # ç™½åŒ–\n",
        "        spectral_density = SpectralDensity(sample_rate=sample_rate, fftlength=2, average=\"median\").to(device)\n",
        "        whiten = Whiten(fduration=2, sample_rate=sample_rate, highpass=20).to(device)\n",
        "\n",
        "        data_batch = data_tensor.unsqueeze(0)\n",
        "        psd_batch = spectral_density(psd_tensor.unsqueeze(0).double())\n",
        "        whitened_batch = whiten(data_batch, psd_batch).float()\n",
        "        whitened_data = whitened_batch\n",
        "\n",
        "        print(\"âœ… æ•¸æ“šè™•ç†å®Œæˆï¼æ­£åœ¨ç¹ªè£½å…©çµ„è¦–åœ–...\")\n",
        "\n",
        "        # æº–å‚™æ•¸æ“š\n",
        "        raw_strain = data_tensor[1].cpu().numpy() # L1\n",
        "        whitened_strain = whitened_data[0, 1].cpu().numpy()\n",
        "\n",
        "        # Bandpass (è®“æ³¢å½¢æ›´ä¹¾æ·¨)\n",
        "        def bandpass_filter(data, fs, low=20, high=100):\n",
        "            nyq = 0.5 * fs\n",
        "            b, a = butter(4, [low/nyq, high/nyq], btype='band')\n",
        "            return filtfilt(b, a, data)\n",
        "        whitened_bp = bandpass_filter(whitened_strain, sample_rate)\n",
        "\n",
        "        # æ™‚é–“è»¸\n",
        "        t_raw = np.linspace(start_time, end_time, len(raw_strain)) - trigger_time\n",
        "        t_white = np.linspace(start_time + 1, end_time - 1, len(whitened_strain)) - trigger_time\n",
        "\n",
        "        # ==========================================\n",
        "        # åœ–ä¸€ï¼šå®è§€å…¨æ™¯ (Global View - 8s)\n",
        "        # ==========================================\n",
        "        fig1, axes1 = plt.subplots(2, 2, figsize=(16, 10))\n",
        "        fig1.suptitle(\"Figure 1: Global View (Full 8s Duration)\", fontsize=16, fontweight='bold')\n",
        "\n",
        "        # å·¦ä¸Šï¼šRaw Time\n",
        "        axes1[0, 0].plot(t_raw, raw_strain, 'gray', alpha=0.8)\n",
        "        axes1[0, 0].set_title(\"Raw Data (Time): Dominated by Low-Freq Noise\")\n",
        "        axes1[0, 0].set_ylabel(\"Strain\"); axes1[0, 0].grid(alpha=0.3)\n",
        "\n",
        "        # å³ä¸Šï¼šProcessed Time\n",
        "        axes1[0, 1].plot(t_white, whitened_bp, 'tab:blue')\n",
        "        axes1[0, 1].set_title(\"Processed Data (Time): Noise Flattened\")\n",
        "        axes1[0, 1].set_ylabel(\"Sigma\"); axes1[0, 1].grid(alpha=0.3)\n",
        "\n",
        "        # å·¦ä¸‹ï¼šRaw Spec\n",
        "        axes1[1, 0].specgram(raw_strain, NFFT=256, Fs=sample_rate, noverlap=128, xextent=[t_raw[0], t_raw[-1]], cmap='inferno', scale='dB')\n",
        "        axes1[1, 0].set_title(\"Raw Spectrogram: High Intensity at Low Freq\")\n",
        "        axes1[1, 0].set_ylabel(\"Freq (Hz)\"); axes1[1, 0].set_yscale('log'); axes1[1, 0].set_ylim(20, 500)\n",
        "\n",
        "        # å³ä¸‹ï¼šProcessed Spec\n",
        "        f, t, Sxx = spectrogram(whitened_strain, fs=sample_rate, nperseg=128, noverlap=120)\n",
        "        axes1[1, 1].pcolormesh(t + t_white[0], f, Sxx, shading='gouraud', cmap='viridis', vmin=0, vmax=10)\n",
        "        axes1[1, 1].set_title(\"Processed Spectrogram: Signal too small to see\")\n",
        "        axes1[1, 1].set_ylabel(\"Freq (Hz)\"); axes1[1, 1].set_ylim(20, 150)\n",
        "\n",
        "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "        plt.show()\n",
        "\n",
        "        # ==========================================\n",
        "        # åœ–äºŒï¼šé¡¯å¾®èšç„¦ (Focused View - 0.6s)\n",
        "        # ==========================================\n",
        "        fig2, axes2 = plt.subplots(2, 2, figsize=(16, 10))\n",
        "        fig2.suptitle(\"Figure 2: Focused View (Zoom-in +/- 0.3s)\", fontsize=16, fontweight='bold')\n",
        "\n",
        "        # è¨­å®š Zoom ç¯„åœ\n",
        "        zoom_range = [-0.3, 0.3]\n",
        "\n",
        "        # å·¦ä¸Šï¼šRaw Time (Zoom)\n",
        "        mask_raw = (t_raw > zoom_range[0]) & (t_raw < zoom_range[1])\n",
        "        axes2[0, 0].plot(t_raw[mask_raw], raw_strain[mask_raw], 'gray', alpha=0.8)\n",
        "        axes2[0, 0].set_title(\"Raw Data (Zoom): Still Random Noise\")\n",
        "        axes2[0, 0].set_ylabel(\"Strain\"); axes2[0, 0].grid(alpha=0.3)\n",
        "\n",
        "        # å³ä¸Šï¼šProcessed Time (Zoom) -> é€™è£¡è¨Šè™Ÿæœƒç¾å½¢ï¼\n",
        "        mask_white = (t_white > zoom_range[0]) & (t_white < zoom_range[1])\n",
        "        axes2[0, 1].plot(t_white[mask_white], whitened_bp[mask_white], 'tab:blue', linewidth=2)\n",
        "        axes2[0, 1].set_title(\"Processed Data (Zoom): GW190521 Waveform Revealed!\")\n",
        "        axes2[0, 1].set_ylabel(\"Sigma\"); axes2[0, 1].grid(alpha=0.3)\n",
        "        # ç•«å€‹è™›ç·šæ¨™ç¤ºä¸­å¿ƒå°±å¥½ï¼Œä¸ç•«ç®­é ­\n",
        "        axes2[0, 1].axvline(0, color='r', linestyle='--', alpha=0.5)\n",
        "\n",
        "        # å·¦ä¸‹ï¼šRaw Spec (Zoom)\n",
        "        axes2[1, 0].specgram(raw_strain, NFFT=256, Fs=sample_rate, noverlap=128, xextent=[t_raw[0], t_raw[-1]], cmap='inferno', scale='dB')\n",
        "        axes2[1, 0].set_title(\"Raw Spectrogram (Zoom): Still Low-Freq Dominant\")\n",
        "        axes2[1, 0].set_ylabel(\"Freq (Hz)\"); axes2[1, 0].set_yscale('log'); axes2[1, 0].set_ylim(20, 500)\n",
        "        axes2[1, 0].set_xlim(zoom_range) # å¼·åˆ¶ Zoom\n",
        "\n",
        "        # å³ä¸‹ï¼šProcessed Spec (Zoom) -> é€™è£¡é »è­œäº®é»æœƒç¾å½¢ï¼\n",
        "        axes2[1, 1].pcolormesh(t + t_white[0], f, Sxx, shading='gouraud', cmap='viridis', vmin=0, vmax=12)\n",
        "        axes2[1, 1].set_title(\"Processed Spectrogram (Zoom): Clear Merger Signal at 60Hz\")\n",
        "        axes2[1, 1].set_ylabel(\"Freq (Hz)\"); axes2[1, 1].set_ylim(20, 150)\n",
        "        axes2[1, 1].set_xlim(zoom_range) # å¼·åˆ¶ Zoom\n",
        "\n",
        "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "        plt.show()\n",
        "\n",
        "        print(\"âœ… é›™è¦–åœ–ç¹ªè£½å®Œæˆï¼\")\n",
        "        print(\"åœ–ä¸€å±•ç¤ºäº†ã€å¤§æµ·æ’ˆé‡ã€çš„é›£åº¦ï¼Œåœ–äºŒå±•ç¤ºäº†ã€æ•¸æ“šè™•ç†ã€çš„å¨åŠ›ã€‚\")\n",
        "\n",
        "    else:\n",
        "        print(\"âŒ æ•¸æ“šä¸‹è¼‰å¤±æ•—ã€‚\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error: {e}\")"
      ],
      "metadata": {
        "id": "XVBpDCM_Z6m5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ç¬¬ä¸‰éƒ¨åˆ†ï¼šç‰©ç†åˆ†æ (é€²éšé …ç›® 1 & 2)\n",
        "\n",
        "åŒ…å«ï¼š\n",
        "\n",
        "1. **ç‰›é “åŠ›å­¸æ“¬åˆ (Inspiral)**ï¼šè­‰æ˜ç°¡å–®ç‰›é “æ¨¡å‹ç„¡æ³•è§£é‡‹æ­¤äº‹ä»¶ï¼ˆç´…ç·šä¸å»åˆï¼‰ã€‚\n",
        "2. **å»£ç¾©ç›¸å°è«–æ“¬åˆ (IMRPhenom)**ï¼šä½¿ç”¨ PyCBC ç”Ÿæˆç›¸å°è«–æ³¢å½¢ï¼Œå®Œç¾é‡ç¾è¨Šè™Ÿï¼ˆç™½ç·šå»åˆï¼‰ã€‚\n",
        "3. **Ringdown åˆ†æ**ï¼šæ“¬åˆåˆä½µå¾Œçš„éˆ´æŒ¯æ³¢å½¢ï¼Œæ¨ç®—é»‘æ´é »ç‡ã€‚"
      ],
      "metadata": {
        "id": "5sZqShdEaCnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 3: ç‰©ç†åˆ†æ (ç‰›é “ vs ç›¸å°è«– + Ringdown) ===\n",
        "if 'whitened_data' not in globals():\n",
        "    print(\"âŒ è«‹å…ˆåŸ·è¡Œ Cell 2ï¼\")\n",
        "else:\n",
        "    strain_l1 = whitened_data[0, 1].cpu().numpy()\n",
        "    plot_start = start_time + 1\n",
        "    plot_end = end_time - 1\n",
        "    time_axis = np.linspace(plot_start, plot_end, len(strain_l1))\n",
        "\n",
        "    plt.figure(figsize=(14, 12))\n",
        "\n",
        "    # --- ä¸Šåœ–ï¼šInspiral & Merger ---\n",
        "    plt.subplot(2, 1, 1)\n",
        "    fs = sample_rate\n",
        "    f_vec, t_vec, Sxx = spectrogram(strain_l1, fs, nperseg=int(fs/16), noverlap=int(fs/16*0.95))\n",
        "    plt.pcolormesh(t_vec + plot_start, f_vec, Sxx, shading='gouraud', cmap='viridis', vmin=0, vmax=15)\n",
        "\n",
        "    # ç‰›é “åŠ›å­¸ (ç´…è™›ç·š)\n",
        "    G, c, M_solar = 6.674e-11, 3e8, 1.989e30\n",
        "    m1, m2 = 85 * M_solar, 66 * M_solar\n",
        "    chirp_mass = (m1 * m2)**(3/5) / (m1 + m2)**(1/5)\n",
        "    def newtonian_freq(t, tc):\n",
        "        tau = tc - t\n",
        "        with np.errstate(invalid='ignore'):\n",
        "            return (c**3)/(8*np.pi*G*chirp_mass) * ((5*G*chirp_mass)/(c**3*tau))**(3/8)\n",
        "\n",
        "    t_model = np.linspace(trigger_time - 1.5, trigger_time, 1000)\n",
        "    plt.plot(t_model, newtonian_freq(t_model, trigger_time+0.02), 'r--', linewidth=3, label='Newtonian')\n",
        "\n",
        "    # å»£ç¾©ç›¸å°è«– (ç™½å¯¦ç·š)\n",
        "    hp, _ = get_td_waveform(approximant=\"IMRPhenomXPHM\", mass1=95, mass2=69, spin1z=0.7, spin2z=0.7, delta_t=1.0/fs, f_lower=20)\n",
        "    hp.resize(len(hp))\n",
        "    rel_time = hp.sample_times.numpy() + (trigger_time - hp.sample_times[-1])\n",
        "    plt.plot(rel_time, hp.numpy() * 400 * 1e19 + 60, 'w-', linewidth=2, alpha=0.9, label='GR Waveform')\n",
        "\n",
        "    plt.yscale('log'); plt.ylim(20, 150); plt.xlim(trigger_time-0.5, trigger_time+0.2)\n",
        "    plt.title(\"Part 1: Newtonian vs GR\", fontsize=14, fontweight='bold'); plt.legend(loc='upper left')\n",
        "\n",
        "    # --- ä¸‹åœ–ï¼šRingdown ---\n",
        "    plt.subplot(2, 1, 2)\n",
        "    peak_idx = np.argmax(np.abs(strain_l1[(time_axis > trigger_time-0.1) & (time_axis < trigger_time+0.1)]))\n",
        "    global_peak_idx = np.where((time_axis > trigger_time-0.1))[0][0] + peak_idx\n",
        "\n",
        "    start_fit = global_peak_idx + int(0.003 * fs)\n",
        "    end_fit = global_peak_idx + int(0.05 * fs)\n",
        "    t_ring = time_axis[start_fit:end_fit]\n",
        "    h_ring = strain_l1[start_fit:end_fit]\n",
        "\n",
        "    def ringdown_model(t, A, tau, f, phi):\n",
        "        return A * np.exp(-(t-t[0])/tau) * np.cos(2*np.pi*f*(t-t[0]) + phi)\n",
        "\n",
        "    try:\n",
        "        popt, _ = curve_fit(ringdown_model, t_ring, h_ring, p0=[np.max(h_ring), 0.01, 65, 0])\n",
        "        plt.plot(time_axis, strain_l1, 'k-', alpha=0.3)\n",
        "        plt.plot(t_ring, ringdown_model(t_ring, *popt), 'r-', linewidth=2.5, label=f'Fit (f={popt[2]:.1f}Hz)')\n",
        "        plt.xlim(trigger_time-0.05, trigger_time+0.1)\n",
        "        plt.title(f\"Part 2: Ringdown (f={popt[2]:.1f} Hz)\", fontsize=14, fontweight='bold'); plt.legend()\n",
        "    except:\n",
        "        print(\"Ringdown fit failed\")\n",
        "\n",
        "    plt.tight_layout(); plt.show()"
      ],
      "metadata": {
        "id": "qY5SlFTiaKOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## ç¬¬å››éƒ¨åˆ†ï¼šæ·±åº¦å­¸ç¿’è¨Šè™Ÿè¾¨è­˜ (é€²éšé …ç›® 3)\n",
        "\n",
        "ä½¿ç”¨ ResNet-18 é€²è¡Œã€Œæœ‰ç›£ç£å­¸ç¿’ã€ã€‚\n",
        "\n",
        "* **æ•¸æ“šå¢å¼·**ï¼šåˆ©ç”¨ `IMRPhenomXPHM` ç”Ÿæˆæ¨¡æ“¬æ³¢å½¢ï¼Œä¸¦æ··åˆçœŸå¯¦é›œè¨Šç‰¹å¾µã€‚\n",
        "* **å»å™ªè™•ç†**ï¼šå¯¦æ–½ Notch Filter (60Hz) ç§»é™¤é›»æºç·šå¹²æ“¾ (PhysRevLett.125.101102æåˆ°) ã€‚\n",
        "* **å¯¦æˆ°é©—è­‰**ï¼šå°‡æ¨¡å‹æ‡‰ç”¨æ–¼çœŸå¯¦ GW190521 æ•¸æ“šã€‚"
      ],
      "metadata": {
        "id": "dAGwQ1azaSn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 4 (ç‰©ç†ä¿®æ­£ç‰ˆ): ç¸®çŸ­çª—å£ (0.5s) èˆ‡ è¨Šè™Ÿå±…ä¸­ ===\n",
        "import concurrent.futures\n",
        "from tqdm.auto import tqdm\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from pycbc.waveform import get_td_waveform\n",
        "from scipy.signal import spectrogram, iirnotch, filtfilt\n",
        "\n",
        "DATA_FILE = \"gw190521_focused_dataset.pt\" # æ”¹å€‹æª”åé¿å…æ··æ·†\n",
        "NUM_SAMPLES = 12000\n",
        "SAMPLE_RATE = 2048\n",
        "DURATION = 0.5 # <--- é—œéµä¿®æ”¹ï¼šåªçœ‹ 0.5 ç§’ï¼Œè®“ 0.1s çš„è¨Šè™Ÿä½”æ¯”è®Šå¤§ï¼\n",
        "\n",
        "def apply_notch(data, fs=2048):\n",
        "    data = np.nan_to_num(data)\n",
        "    for f in [60, 120, 180]:\n",
        "        b, a = iirnotch(f, 30, fs)\n",
        "        data = filtfilt(b, a, data)\n",
        "    return np.nan_to_num(data)\n",
        "\n",
        "def get_ai_spec(strain, fs=2048):\n",
        "    # nperseg=128 é©åˆçŸ­çª—å£ï¼Œæ™‚é–“è§£æåº¦è¼ƒé«˜\n",
        "    f, t, Sxx = spectrogram(strain, fs=fs, nperseg=128, noverlap=120)\n",
        "\n",
        "    # é »ç‡åªå– 20-150Hz (é»‘æ´åˆä½µä¸»è¦é »æ®µï¼Œå»é™¤éå¿…è¦çš„é«˜é »ç©ºç™½)\n",
        "    mask = (f >= 20) & (f <= 150)\n",
        "    spec = np.log(Sxx[mask, :] + 1e-10)\n",
        "    spec = np.clip(spec, np.mean(spec)-2.0*np.std(spec), np.mean(spec)+3.0*np.std(spec))\n",
        "    return (spec - np.min(spec)) / (np.max(spec) - np.min(spec) + 1e-8)\n",
        "\n",
        "def worker(i):\n",
        "    np.random.seed(int.from_bytes(os.urandom(4), 'little'))\n",
        "\n",
        "    # 1. ç”¢ç”Ÿç¸½é•·åº¦ (ç”Ÿæˆé•·ä¸€é»ä»¥å…é‚Šç·£æ•ˆæ‡‰)\n",
        "    N_gen = int(SAMPLE_RATE * 2.0)\n",
        "    noise = np.random.normal(0, 0.5, N_gen)\n",
        "\n",
        "    # 2. å®šç¾©æœ€çµ‚æ“·å–çš„è¦–çª—ä¸­å¿ƒ\n",
        "    center_idx = N_gen // 2\n",
        "    half_window = int(SAMPLE_RATE * DURATION / 2)\n",
        "\n",
        "    if i % 2 == 0: # Signal\n",
        "        # ç”Ÿæˆæ³¢å½¢\n",
        "        hp, _ = get_td_waveform(approximant=\"IMRPhenomXPHM\",\n",
        "                                mass1=np.random.uniform(60, 100), # é‡å° GW190521 çš„è³ªé‡ç¯„åœ\n",
        "                                mass2=np.random.uniform(40, 80),\n",
        "                                delta_t=1.0/SAMPLE_RATE,\n",
        "                                f_lower=20)\n",
        "        hp.resize(len(hp))\n",
        "        sig_raw = hp.numpy()\n",
        "\n",
        "        # æ‰¾åˆ°è¨Šè™Ÿå³°å€¼ (Merger)\n",
        "        peak_idx_sig = np.argmax(np.abs(sig_raw))\n",
        "\n",
        "        # å°‡è¨Šè™Ÿå³°å€¼å°é½Šåˆ°å™ªè²ä¸­å¿ƒ (Center Alignment)\n",
        "        # ä¸¦åŠ å…¥ä¸€é»é»éš¨æ©ŸæŠ–å‹• (Jitter +/- 0.05s)ï¼Œé¿å…æ¨¡å‹åªå­¸æœƒã€Œæ­£ä¸­é–“æœ‰æ±è¥¿ã€\n",
        "        jitter = np.random.randint(-int(0.05*SAMPLE_RATE), int(0.05*SAMPLE_RATE))\n",
        "        place_idx = center_idx + jitter\n",
        "\n",
        "        # ç–ŠåŠ \n",
        "        start_sig = place_idx - peak_idx_sig\n",
        "        end_sig = start_sig + len(sig_raw)\n",
        "\n",
        "        # é‚Šç•Œæª¢æŸ¥\n",
        "        valid_start = max(0, start_sig)\n",
        "        valid_end = min(N_gen, end_sig)\n",
        "\n",
        "        sig_offset = valid_start - start_sig\n",
        "        sig_len = valid_end - valid_start\n",
        "\n",
        "        if sig_len > 0:\n",
        "            # === ä¿®æ­£é»ï¼šå¤§å¹…é™ä½ SNR ===\n",
        "            # åŸæœ¬æ˜¯ 10.0 ~ 20.0 (å¤ªäº®äº†)\n",
        "            # æ”¹æˆ 1.0 ~ 3.5 (é€™æ‰æ˜¯æœ‰æŒ‘æˆ°æ€§çš„çœŸå¯¦å¼·åº¦)\n",
        "            # ç”šè‡³å¯ä»¥è¨­åˆ° 0.5 ~ 2.0 ä¾†æ¨¡æ“¬æ¥µé™åµæ¸¬\n",
        "            amp_scale = np.random.uniform(1.0, 3.5)\n",
        "            noise[valid_start:valid_end] += sig_raw[sig_offset : sig_offset+sig_len] * 1e19 * amp_scale\n",
        "\n",
        "        # æ“·å–ä¸­å¿ƒ 0.5s\n",
        "        final_data = noise[center_idx-half_window : center_idx+half_window]\n",
        "        return get_ai_spec(apply_notch(final_data)), 1.0\n",
        "\n",
        "    else: # Noise\n",
        "        # ç´”é›œè¨Šä¹Ÿå–ä¸­å¿ƒ\n",
        "        final_data = noise[center_idx-half_window : center_idx+half_window]\n",
        "        return get_ai_spec(apply_notch(final_data)), 0.0\n",
        "\n",
        "if os.path.exists(DATA_FILE):\n",
        "    os.remove(DATA_FILE)\n",
        "\n",
        "print(f\"ğŸš€ ç”Ÿæˆã€Œèšç„¦ç‰ˆã€æ•¸æ“š (Window={DURATION}s, Target=GW190521)...\")\n",
        "with concurrent.futures.ProcessPoolExecutor() as ex:\n",
        "    results = list(tqdm(ex.map(worker, range(NUM_SAMPLES)), total=NUM_SAMPLES))\n",
        "\n",
        "data, labels = zip(*results)\n",
        "data_tensor = torch.tensor(np.array(data)).unsqueeze(1).float()\n",
        "labels_tensor = torch.tensor(np.array(labels)).unsqueeze(1).float()\n",
        "torch.save({\"data\": data_tensor, \"labels\": labels_tensor}, DATA_FILE)\n",
        "print(\"âœ… æ•¸æ“šç”Ÿæˆå®Œç•¢ï¼\")"
      ],
      "metadata": {
        "id": "WW72Lz3saYuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 5 (æ¨¡å‹å‡ç´šç‰ˆ): EfficientNet-B0 + è¦–è¦ºåŒ– ===\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "DATA_FILE = \"gw190521_focused_dataset.pt\"\n",
        "\n",
        "class WaveDataset(Dataset):\n",
        "    def __init__(self, tensors, labels, transform=None):\n",
        "        self.tensors = tensors\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.tensors[index]\n",
        "        y = self.labels[index]\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tensors)\n",
        "\n",
        "if os.path.exists(DATA_FILE):\n",
        "    saved = torch.load(DATA_FILE)\n",
        "    full_data = saved[\"data\"]\n",
        "    full_labels = saved[\"labels\"]\n",
        "\n",
        "    # Transform: ä¾ç„¶æ”¾å¤§åˆ° 224 ä»¥ç¬¦åˆ EfficientNet çš„é è¨“ç·´è¨­è¨ˆ\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomApply([transforms.RandomAffine(degrees=0, translate=(0.05, 0.05))], p=0.3),\n",
        "    ])\n",
        "    val_transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224))\n",
        "    ])\n",
        "\n",
        "    # Split\n",
        "    total_len = len(full_data)\n",
        "    train_len = int(0.8 * total_len)\n",
        "    generator = torch.Generator().manual_seed(42)\n",
        "    perm = torch.randperm(total_len, generator=generator)\n",
        "\n",
        "    train_ds = WaveDataset(full_data[perm[:train_len]], full_labels[perm[:train_len]], transform=train_transform)\n",
        "    val_ds = WaveDataset(full_data[perm[train_len:]], full_labels[perm[train_len:]], transform=val_transform)\n",
        "    train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "    val_dl = DataLoader(val_ds, batch_size=32)\n",
        "\n",
        "    # === è¦–è¦ºåŒ–æª¢æŸ¥ ===\n",
        "    print(\"ğŸ§ æª¢æŸ¥æ–°æ•¸æ“š (0.5s è¦–çª—):\")\n",
        "    sample_img, sample_lbl = next(iter(DataLoader(train_ds, batch_size=4, shuffle=True)))\n",
        "    plt.figure(figsize=(12, 3))\n",
        "    for i in range(4):\n",
        "        plt.subplot(1, 4, i+1)\n",
        "        plt.imshow(sample_img[i].squeeze().numpy(), origin='lower', aspect='auto', cmap='magma')\n",
        "        plt.title(f\"Label: {sample_lbl[i].item()}\")\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "    # =================\n",
        "\n",
        "    # === æ¨¡å‹æ›´æ›ï¼šEfficientNet-B0 ===\n",
        "    print(\"ğŸ› ï¸ è¼‰å…¥ EfficientNet_B0...\")\n",
        "    try:\n",
        "        model = models.efficientnet_b0(weights=None)\n",
        "        # ä¿®æ”¹ç¬¬ä¸€å±¤ (Conv2d): è¼¸å…¥å¾ 3 é€šé“æ”¹ç‚º 1 é€šé“\n",
        "        # EfficientNet çš„ç¬¬ä¸€å±¤çµæ§‹æ˜¯ model.features[0][0]\n",
        "        first_conv_layer = model.features[0][0]\n",
        "        model.features[0][0] = nn.Conv2d(1, first_conv_layer.out_channels,\n",
        "                                         kernel_size=first_conv_layer.kernel_size,\n",
        "                                         stride=first_conv_layer.stride,\n",
        "                                         padding=first_conv_layer.padding,\n",
        "                                         bias=False)\n",
        "\n",
        "        # ä¿®æ”¹æœ€å¾Œä¸€å±¤ (Classifier): è¼¸å‡ºæ”¹ç‚º 1\n",
        "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, 1)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ EfficientNet è¼‰å…¥å¤±æ•— ({e})ï¼Œåˆ‡æ›å› ResNet18...\")\n",
        "        model = models.resnet18(weights=None)\n",
        "        model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        model.fc = nn.Linear(model.fc.in_features, 1)\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    # è¨“ç·´è¨­å®š\n",
        "    opt = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "    crit = nn.BCEWithLogitsLoss()\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(opt, mode='max', factor=0.5, patience=2)\n",
        "\n",
        "    # è¨“ç·´è¿´åœˆ\n",
        "    epochs = 10\n",
        "    best_acc = 0.0\n",
        "    hist = {'train':[], 'val':[], 'acc':[]}\n",
        "\n",
        "    print(f\"ğŸš€ é–‹å§‹è¨“ç·´ (Window=0.5s)...\")\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        run_loss = 0\n",
        "        for x, y in train_dl:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            opt.zero_grad()\n",
        "            out = model(x)\n",
        "            loss = crit(out, y)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            run_loss += loss.item()\n",
        "\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for x, y in val_dl:\n",
        "                x, y = x.to(device), y.to(device)\n",
        "                out = model(x)\n",
        "                val_loss += crit(out, y).item()\n",
        "                correct += ((torch.sigmoid(out)>0.5) == y).sum().item()\n",
        "\n",
        "        acc = correct / len(val_ds)\n",
        "        hist['train'].append(run_loss/len(train_dl))\n",
        "        hist['val'].append(val_loss/len(val_dl))\n",
        "        hist['acc'].append(acc)\n",
        "        scheduler.step(acc)\n",
        "\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            print(f\"Epoch {epoch+1} | Train: {hist['train'][-1]:.4f} | Val: {hist['val'][-1]:.4f} | Acc: {acc:.2%} (Best!)\")\n",
        "        else:\n",
        "            print(f\"Epoch {epoch+1} | Train: {hist['train'][-1]:.4f} | Acc: {acc:.2%}\")\n",
        "\n",
        "    print(f\"ğŸ† æœ€çµ‚æœ€ä½³æº–ç¢ºç‡: {best_acc:.2%}\")\n",
        "else:\n",
        "    print(\"âŒ è«‹å…ˆåŸ·è¡Œæ–°çš„ Cell 4ï¼\")"
      ],
      "metadata": {
        "id": "-EMv86Z2h5qR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 6: æœ€çµ‚ AI é©—æ”¶ (Signal vs Noise) ===\n",
        "# ç¢ºä¿ä½¿ç”¨èˆ‡è¨“ç·´ä¸€è‡´çš„é è™•ç†\n",
        "def get_ai_spec(strain, fs=2048):\n",
        "    f, t, Sxx = spectrogram(strain, fs=fs, nperseg=256, noverlap=240)\n",
        "    mask = (f >= 20) & (f <= 300)\n",
        "    spec = np.log(Sxx[mask, :] + 1e-10)\n",
        "    spec = np.clip(spec, np.mean(spec)-2.5*np.std(spec), np.mean(spec)+2.5*np.std(spec))\n",
        "    return (spec - np.min(spec)) / (np.max(spec) - np.min(spec) + 1e-8), t, f[mask]\n",
        "\n",
        "# æŠ“å–çœŸå¯¦æ•¸æ“š\n",
        "idx_sig = int(5.0 * sample_rate)\n",
        "idx_noise = int(2.0 * sample_rate)\n",
        "hw = int(0.5 * sample_rate)\n",
        "\n",
        "sig_data = whitened_data[0, 1, idx_sig-hw:idx_sig+hw].cpu().numpy()\n",
        "noise_data = whitened_data[0, 1, idx_noise-hw:idx_noise+hw].cpu().numpy()\n",
        "\n",
        "# é æ¸¬\n",
        "model.eval()\n",
        "spec_sig, _, f_axis = get_ai_spec(sig_data)\n",
        "spec_noise, _, _ = get_ai_spec(noise_data)\n",
        "\n",
        "with torch.no_grad():\n",
        "    score_sig = torch.sigmoid(model(torch.tensor(spec_sig).unsqueeze(0).unsqueeze(0).float().to(device))).item()\n",
        "    score_noise = torch.sigmoid(model(torch.tensor(spec_noise).unsqueeze(0).unsqueeze(0).float().to(device))).item()\n",
        "\n",
        "# ç¹ªåœ–\n",
        "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
        "ax[0].imshow(spec_sig, origin='lower', aspect='auto', cmap='viridis', extent=[-0.5, 0.5, f_axis[0], f_axis[-1]])\n",
        "ax[0].set_title(f\"Target: Signal\\nConf: {score_sig:.4f}\", color='green', fontweight='bold')\n",
        "ax[0].axvline(0, color='r', linestyle='--')\n",
        "\n",
        "ax[1].imshow(spec_noise, origin='lower', aspect='auto', cmap='viridis', extent=[-0.5, 0.5, f_axis[0], f_axis[-1]])\n",
        "ax[1].set_title(f\"Control: Noise\\nConf: {score_noise:.4f}\", color='black', fontweight='bold')\n",
        "\n",
        "plt.show()\n",
        "print(f\"ğŸš€ AI åˆ¤æ–·ï¼šè¨Šè™Ÿä¿¡å¿ƒåº¦ {score_sig:.2%} | é›œè¨Šèª¤åˆ¤ç‡ {score_noise:.2%}\")"
      ],
      "metadata": {
        "id": "SJnqc1EAjsLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 7 (ä¿®æ­£ç‰ˆ): è£½ä½œæ³¢å½¢æƒæå‹•ç•«ä¸¦å­˜æª” (MP4/GIF) ===\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from matplotlib import rc\n",
        "import numpy as np\n",
        "\n",
        "# 1. è§£é™¤å‹•ç•«å¤§å°é™åˆ¶ (è¨­ç‚º 100MB)\n",
        "plt.rcParams['animation.embed_limit'] = 100.0\n",
        "# è¨­å®š ffmpeg (ç”¨æ–¼ç”Ÿæˆ MP4)\n",
        "rc('animation', html='jshtml')\n",
        "\n",
        "print(\"æ­£åœ¨è£½ä½œä¸¦å„²å­˜å‹•ç•«ï¼Œè«‹ç¨å€™...\")\n",
        "\n",
        "# 2. æº–å‚™æ•¸æ“š\n",
        "# ç‚ºäº†é¿å…æª”æ¡ˆéå¤§ï¼Œæˆ‘å€‘åªå–æœ€ç²¾å½©çš„ 1 ç§’é˜ (Trigger å‰å¾Œ 0.5s)\n",
        "center_idx = int(5.0 * sample_rate)\n",
        "window = int(0.5 * sample_rate)\n",
        "data_anim = whitened_data[0, 1, center_idx-window : center_idx+window].cpu().numpy()\n",
        "\n",
        "# ç°¡å–®æ¿¾æ³¢è®“ç·šæ¢å¥½çœ‹é»\n",
        "def apply_notch_anim(data, fs=2048):\n",
        "    from scipy.signal import iirnotch, filtfilt\n",
        "    data = np.nan_to_num(data)\n",
        "    for f in [60, 120, 180]:\n",
        "        b, a = iirnotch(f, 30, fs)\n",
        "        data = filtfilt(b, a, data)\n",
        "    return data\n",
        "\n",
        "data_anim = apply_notch_anim(data_anim, sample_rate)\n",
        "t_anim = np.linspace(-0.5, 0.5, len(data_anim))\n",
        "\n",
        "# 3. è¨­å®šç•«å¸ƒ (èª¿æ•´ figsize å’Œ DPI ä»¥æ§åˆ¶æª”æ¡ˆå¤§å°)\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 6), dpi=100, sharex=True)\n",
        "\n",
        "# ä¸Šåœ–ï¼šæ³¢å½¢\n",
        "line, = ax1.plot([], [], 'w-', linewidth=1.5)\n",
        "ax1.set_xlim(-0.5, 0.2)\n",
        "ax1.set_ylim(-6, 6)\n",
        "ax1.set_facecolor('black')\n",
        "ax1.set_ylabel('Strain', color='white')\n",
        "ax1.set_title('GW190521 Merger Event', fontsize=14)\n",
        "ax1.grid(True, alpha=0.3, color='gray')\n",
        "\n",
        "# ä¸‹åœ–ï¼šé »è­œåœ–\n",
        "from scipy.signal import spectrogram\n",
        "f, t, Sxx = spectrogram(data_anim, fs=sample_rate, nperseg=128, noverlap=120)\n",
        "t = t - 0.5 # æ ¡æ­£æ™‚é–“\n",
        "mesh = ax2.pcolormesh(t, f, Sxx, shading='gouraud', cmap='viridis', vmin=0, vmax=10)\n",
        "ax2.set_ylabel('Frequency (Hz)')\n",
        "ax2.set_xlabel('Time (s)')\n",
        "ax2.set_ylim(20, 150)\n",
        "ax2.set_facecolor('black')\n",
        "\n",
        "# æƒæç·š\n",
        "vline1 = ax1.axvline(x=-0.5, color='r', linestyle='--')\n",
        "vline2 = ax2.axvline(x=-0.5, color='r', linestyle='--')\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# 4. æ›´æ–°å‡½æ•¸\n",
        "def update(frame):\n",
        "    current_time = t_anim[frame]\n",
        "    # æ›´æ–°æ³¢å½¢\n",
        "    line.set_data(t_anim[:frame], data_anim[:frame])\n",
        "    # æ›´æ–°æƒæç·š\n",
        "    vline1.set_xdata([current_time])\n",
        "    vline2.set_xdata([current_time])\n",
        "    return line, vline1, vline2\n",
        "\n",
        "# 5. ç”Ÿæˆå‹•ç•« (é™ä½æ¡æ¨£ç‡ Step=4 ä»¥ç¸®å°é«”ç©)\n",
        "step = 4\n",
        "frames = range(0, len(t_anim), step)\n",
        "ani = animation.FuncAnimation(fig, update, frames=frames, interval=20, blit=True)\n",
        "\n",
        "# === é—œéµä¿®æ”¹ï¼šå­˜æˆç¨ç«‹æª”æ¡ˆ ===\n",
        "# å„²å­˜ MP4 (PPT é¦–é¸ï¼Œç•«è³ªå¥½é«”ç©å°)\n",
        "print(\"æ­£åœ¨å„²å­˜ç‚º gw190521.mp4 ...\")\n",
        "ani.save('gw190521.mp4', writer='ffmpeg', fps=30)\n",
        "\n",
        "# å„²å­˜ GIF (å‚™ç”¨ï¼Œç›¸å®¹æ€§é«˜ä½†é«”ç©å¤§)\n",
        "print(\"æ­£åœ¨å„²å­˜ç‚º gw190521.gif ...\")\n",
        "ani.save('gw190521.gif', writer='pillow', fps=15)\n",
        "\n",
        "plt.close()\n",
        "print(\"âœ… å‹•ç•«è£½ä½œå®Œæˆï¼\")\n",
        "print(\"ğŸ“¥ è«‹æŸ¥çœ‹å·¦å´æª”æ¡ˆæ¬„ (Files)ï¼Œä¸‹è¼‰ 'gw190521.mp4' æˆ– 'gw190521.gif' æ”¾å…¥æŠ•å½±ç‰‡ã€‚\")"
      ],
      "metadata": {
        "id": "B7RKsRvhox0L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}